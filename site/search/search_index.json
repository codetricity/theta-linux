{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"RICOH THETA Development on Linux Overview Stream 360 video, control the RICOH THETA API, and supply power to the camera using the USB cable. It's awesome! Video to your Linux computer is 4K at 30fps with under 30ms latency. Works with the RICOH THETA V or RICOH THETA Z1. It's perfect for OpenCV object detection, autonomous drones, building analysis, AI, and TensorFlow projects. The camera can be powered from the USB cable and can switch into live streaming mode, still image, video, or bracket shooting using API commands. We explain the tools, the repos, and the API. Up to date guides, events, and a general pile of great stuff is at the theta360.guide Linux Streaming Site . It's an exciting world. Let's getting started.","title":"Home"},{"location":"#ricoh-theta-development-on-linux","text":"","title":"RICOH THETA Development on Linux"},{"location":"#overview","text":"Stream 360 video, control the RICOH THETA API, and supply power to the camera using the USB cable. It's awesome! Video to your Linux computer is 4K at 30fps with under 30ms latency. Works with the RICOH THETA V or RICOH THETA Z1. It's perfect for OpenCV object detection, autonomous drones, building analysis, AI, and TensorFlow projects. The camera can be powered from the USB cable and can switch into live streaming mode, still image, video, or bracket shooting using API commands. We explain the tools, the repos, and the API. Up to date guides, events, and a general pile of great stuff is at the theta360.guide Linux Streaming Site . It's an exciting world. Let's getting started.","title":"Overview"},{"location":"demos/","text":"Ongoing Tests with Linux Streaming Using Nvidia Jetson Nano live streaming from a THETA V. Processing done with Python3, OpenCV 4.4. Scroll down for code. DetectNet Running live on Jetson Nano with RICOH THETA Z1. DetectNet applied to both single frame with SSD Mobilenet-v2 to assess accuracy and to live stream to assess framerate. Works good on both. Video demo with Jetson Nano . See Jetson Nano inference benchmarks . Code is available in the at https://github.com/dusty-nv/jetson-inference There is super small text in the green box that says, \"person\". The system accurately detected the only person in the image. It is 88.6 percent confident that I am a person. Nice. Despite the distorted view of my feet, the program does detect the human form. Even at night, in low-light conditions with me on the side of the shutter button, the program did detect me. However, there were many frames where I was not detected. To proceed, you will likely need a database of fisheye or equirectangular images to build your own model. Sample Code import jetson.inference import jetson.utils net = jetson.inference.detectNet(\"ssd-mobilenet-v2\", threshold=0.5) camera = jetson.utils.gstCamera(1280, 720, \"/dev/video0\") display = jetson.utils.glDisplay() while display.IsOpen(): img, width, height = camera.CaptureRGBA() detections = net.Detect(img, width, height) display.RenderOnce(img, width, height) display.SetTitle(\"RICOH THETA Detection | Network {:.0f} FPS\".format(net.GetNetworkFPS())) OpenCV Python Works on live stream. Procedure install libuvc-theta install libuv-theta-sample install v4l2loopback load kernel modules for v4l2loopback and verify that /dev/video0 or equivalent shows THETA stream run Python script with cv2 Recommend you recompile OpenCV 4.4 from source code. May take 2.5 hours if you compile on the Nano. Simple Python cv2 Test Frame resize test. import cv2 cap = cv2.VideoCapture(0) # Check if the webcam is opened correctly if not cap.isOpened(): raise IOError(\"Cannot open webcam\") while True: ret, frame = cap.read() frame = cv2.resize(frame, None, fx=0.25, fy=0.25, interpolation=cv2.INTER_AREA) cv2.imshow('Input', frame) c = cv2.waitKey(1) if c == 27: break cap.release() cv2.destroyAllWindows() Build OpenCV One script to install OpenCV 4.3 is from AastaNV here . The script I used is from mdegans here Canny Edge Detection Test Code for OpenCV Demo with Canny from RICOH THETA V . This is the edge detection demo with the white lines on black background. video demo import sys import argparse import cv2 import numpy as np def parse_cli_args(): parser = argparse.ArgumentParser() parser.add_argument(\"--video_device\", dest=\"video_device\", help=\"Video device # of USB webcam (/dev/video?) [0]\", default=0, type=int) arguments = parser.parse_args() return arguments # On versions of L4T previous to L4T 28.1, flip-method=2 # Use the Jetson onboard camera def open_onboard_camera(): return cv2.VideoCapture(0) # Open an external usb camera /dev/videoX def open_camera_device(device_number): return cv2.VideoCapture(device_number) def read_cam(video_capture): if video_capture.isOpened(): windowName = \"main_canny\" cv2.namedWindow(windowName, cv2.WINDOW_NORMAL) cv2.resizeWindow(windowName,1280,720) cv2.moveWindow(windowName,0,0) cv2.setWindowTitle(windowName,\"RICOH THETA OpenCV Python Demo\") showWindow=3 # Show all stages showHelp = True font = cv2.FONT_HERSHEY_PLAIN helpText=\"'Esc' to Quit, '1' for Camera Feed, '2' for Canny Detection, '3' for All Stages. '4' to hide help\" edgeThreshold=40 showFullScreen = False while True: if cv2.getWindowProperty(windowName, 0) < 0: # Check to see if the user closed the window # This will fail if the user closed the window; Nasties get printed to the console break; ret_val, frame = video_capture.read(); hsv=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) blur=cv2.GaussianBlur(hsv,(7,7),1.5) edges=cv2.Canny(blur,0,edgeThreshold) if showWindow == 3: # Need to show the 4 stages # Composite the 2x2 window # Feed from the camera is RGB, the others gray # To composite, convert gray images to color. # All images must be of the same type to display in a window frameRs=cv2.resize(frame, (640,360)) hsvRs=cv2.resize(hsv,(640,360)) vidBuf = np.concatenate((frameRs, cv2.cvtColor(hsvRs,cv2.COLOR_GRAY2BGR)), axis=1) blurRs=cv2.resize(blur,(640,360)) edgesRs=cv2.resize(edges,(640,360)) vidBuf1 = np.concatenate( (cv2.cvtColor(blurRs,cv2.COLOR_GRAY2BGR),cv2.cvtColor(edgesRs,cv2.COLOR_GRAY2BGR)), axis=1) vidBuf = np.concatenate( (vidBuf, vidBuf1), axis=0) if showWindow==1: # Show Camera Frame displayBuf = frame elif showWindow == 2: # Show Canny Edge Detection displayBuf = edges elif showWindow == 3: # Show All Stages displayBuf = vidBuf if showHelp == True: cv2.putText(displayBuf, helpText, (11,20), font, 1.0, (32,32,32), 4, cv2.LINE_AA) cv2.putText(displayBuf, helpText, (10,20), font, 1.0, (240,240,240), 1, cv2.LINE_AA) cv2.imshow(windowName,displayBuf) key=cv2.waitKey(10) if key == 27: # Check for ESC key cv2.destroyAllWindows() break ; elif key==49: # 1 key, show frame cv2.setWindowTitle(windowName,\"Camera Feed\") showWindow=1 elif key==50: # 2 key, show Canny cv2.setWindowTitle(windowName,\"Canny Edge Detection\") showWindow=2 elif key==51: # 3 key, show Stages cv2.setWindowTitle(windowName,\"Camera, Gray scale, Gaussian Blur, Canny Edge Detection\") showWindow=3 elif key==52: # 4 key, toggle help showHelp = not showHelp elif key==44: # , lower canny edge threshold edgeThreshold=max(0,edgeThreshold-1) print ('Canny Edge Threshold Maximum: ',edgeThreshold) elif key==46: # , raise canny edge threshold edgeThreshold=edgeThreshold+1 print ('Canny Edge Threshold Maximum: ', edgeThreshold) elif key==74: # Toggle fullscreen; This is the F3 key on this particular keyboard # Toggle full screen mode if showFullScreen == False : cv2.setWindowProperty(windowName, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN) else: cv2.setWindowProperty(windowName, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL) showFullScreen = not showFullScreen else: print (\"camera open failed\") if __name__ == '__main__': arguments = parse_cli_args() print(\"Called with args:\") print(arguments) print(\"OpenCV version: {}\".format(cv2.__version__)) print(\"Device Number:\",arguments.video_device) if arguments.video_device==0: video_capture=open_onboard_camera() else: video_capture=open_camera_device(arguments.video_device) read_cam(video_capture) video_capture.release() cv2.destroyAllWindows() OpenPose Works on live stream with Jetpack 4.3, not 4.4.","title":"Demos"},{"location":"demos/#ongoing-tests-with-linux-streaming","text":"Using Nvidia Jetson Nano live streaming from a THETA V. Processing done with Python3, OpenCV 4.4. Scroll down for code.","title":"Ongoing Tests with Linux Streaming"},{"location":"demos/#detectnet","text":"Running live on Jetson Nano with RICOH THETA Z1. DetectNet applied to both single frame with SSD Mobilenet-v2 to assess accuracy and to live stream to assess framerate. Works good on both. Video demo with Jetson Nano . See Jetson Nano inference benchmarks . Code is available in the at https://github.com/dusty-nv/jetson-inference There is super small text in the green box that says, \"person\". The system accurately detected the only person in the image. It is 88.6 percent confident that I am a person. Nice. Despite the distorted view of my feet, the program does detect the human form. Even at night, in low-light conditions with me on the side of the shutter button, the program did detect me. However, there were many frames where I was not detected. To proceed, you will likely need a database of fisheye or equirectangular images to build your own model.","title":"DetectNet"},{"location":"demos/#sample-code","text":"import jetson.inference import jetson.utils net = jetson.inference.detectNet(\"ssd-mobilenet-v2\", threshold=0.5) camera = jetson.utils.gstCamera(1280, 720, \"/dev/video0\") display = jetson.utils.glDisplay() while display.IsOpen(): img, width, height = camera.CaptureRGBA() detections = net.Detect(img, width, height) display.RenderOnce(img, width, height) display.SetTitle(\"RICOH THETA Detection | Network {:.0f} FPS\".format(net.GetNetworkFPS()))","title":"Sample Code"},{"location":"demos/#opencv-python","text":"Works on live stream.","title":"OpenCV Python"},{"location":"demos/#procedure","text":"install libuvc-theta install libuv-theta-sample install v4l2loopback load kernel modules for v4l2loopback and verify that /dev/video0 or equivalent shows THETA stream run Python script with cv2 Recommend you recompile OpenCV 4.4 from source code. May take 2.5 hours if you compile on the Nano.","title":"Procedure"},{"location":"demos/#simple-python-cv2-test","text":"Frame resize test. import cv2 cap = cv2.VideoCapture(0) # Check if the webcam is opened correctly if not cap.isOpened(): raise IOError(\"Cannot open webcam\") while True: ret, frame = cap.read() frame = cv2.resize(frame, None, fx=0.25, fy=0.25, interpolation=cv2.INTER_AREA) cv2.imshow('Input', frame) c = cv2.waitKey(1) if c == 27: break cap.release() cv2.destroyAllWindows()","title":"Simple Python cv2 Test"},{"location":"demos/#build-opencv","text":"One script to install OpenCV 4.3 is from AastaNV here . The script I used is from mdegans here","title":"Build OpenCV"},{"location":"demos/#canny-edge-detection-test","text":"Code for OpenCV Demo with Canny from RICOH THETA V . This is the edge detection demo with the white lines on black background. video demo import sys import argparse import cv2 import numpy as np def parse_cli_args(): parser = argparse.ArgumentParser() parser.add_argument(\"--video_device\", dest=\"video_device\", help=\"Video device # of USB webcam (/dev/video?) [0]\", default=0, type=int) arguments = parser.parse_args() return arguments # On versions of L4T previous to L4T 28.1, flip-method=2 # Use the Jetson onboard camera def open_onboard_camera(): return cv2.VideoCapture(0) # Open an external usb camera /dev/videoX def open_camera_device(device_number): return cv2.VideoCapture(device_number) def read_cam(video_capture): if video_capture.isOpened(): windowName = \"main_canny\" cv2.namedWindow(windowName, cv2.WINDOW_NORMAL) cv2.resizeWindow(windowName,1280,720) cv2.moveWindow(windowName,0,0) cv2.setWindowTitle(windowName,\"RICOH THETA OpenCV Python Demo\") showWindow=3 # Show all stages showHelp = True font = cv2.FONT_HERSHEY_PLAIN helpText=\"'Esc' to Quit, '1' for Camera Feed, '2' for Canny Detection, '3' for All Stages. '4' to hide help\" edgeThreshold=40 showFullScreen = False while True: if cv2.getWindowProperty(windowName, 0) < 0: # Check to see if the user closed the window # This will fail if the user closed the window; Nasties get printed to the console break; ret_val, frame = video_capture.read(); hsv=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) blur=cv2.GaussianBlur(hsv,(7,7),1.5) edges=cv2.Canny(blur,0,edgeThreshold) if showWindow == 3: # Need to show the 4 stages # Composite the 2x2 window # Feed from the camera is RGB, the others gray # To composite, convert gray images to color. # All images must be of the same type to display in a window frameRs=cv2.resize(frame, (640,360)) hsvRs=cv2.resize(hsv,(640,360)) vidBuf = np.concatenate((frameRs, cv2.cvtColor(hsvRs,cv2.COLOR_GRAY2BGR)), axis=1) blurRs=cv2.resize(blur,(640,360)) edgesRs=cv2.resize(edges,(640,360)) vidBuf1 = np.concatenate( (cv2.cvtColor(blurRs,cv2.COLOR_GRAY2BGR),cv2.cvtColor(edgesRs,cv2.COLOR_GRAY2BGR)), axis=1) vidBuf = np.concatenate( (vidBuf, vidBuf1), axis=0) if showWindow==1: # Show Camera Frame displayBuf = frame elif showWindow == 2: # Show Canny Edge Detection displayBuf = edges elif showWindow == 3: # Show All Stages displayBuf = vidBuf if showHelp == True: cv2.putText(displayBuf, helpText, (11,20), font, 1.0, (32,32,32), 4, cv2.LINE_AA) cv2.putText(displayBuf, helpText, (10,20), font, 1.0, (240,240,240), 1, cv2.LINE_AA) cv2.imshow(windowName,displayBuf) key=cv2.waitKey(10) if key == 27: # Check for ESC key cv2.destroyAllWindows() break ; elif key==49: # 1 key, show frame cv2.setWindowTitle(windowName,\"Camera Feed\") showWindow=1 elif key==50: # 2 key, show Canny cv2.setWindowTitle(windowName,\"Canny Edge Detection\") showWindow=2 elif key==51: # 3 key, show Stages cv2.setWindowTitle(windowName,\"Camera, Gray scale, Gaussian Blur, Canny Edge Detection\") showWindow=3 elif key==52: # 4 key, toggle help showHelp = not showHelp elif key==44: # , lower canny edge threshold edgeThreshold=max(0,edgeThreshold-1) print ('Canny Edge Threshold Maximum: ',edgeThreshold) elif key==46: # , raise canny edge threshold edgeThreshold=edgeThreshold+1 print ('Canny Edge Threshold Maximum: ', edgeThreshold) elif key==74: # Toggle fullscreen; This is the F3 key on this particular keyboard # Toggle full screen mode if showFullScreen == False : cv2.setWindowProperty(windowName, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN) else: cv2.setWindowProperty(windowName, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL) showFullScreen = not showFullScreen else: print (\"camera open failed\") if __name__ == '__main__': arguments = parse_cli_args() print(\"Called with args:\") print(arguments) print(\"OpenCV version: {}\".format(cv2.__version__)) print(\"Device Number:\",arguments.video_device) if arguments.video_device==0: video_capture=open_onboard_camera() else: video_capture=open_camera_device(arguments.video_device) read_cam(video_capture) video_capture.release() cv2.destroyAllWindows()","title":"Canny Edge Detection Test"},{"location":"demos/#openpose","text":"Works on live stream with Jetpack 4.3, not 4.4.","title":"OpenPose"},{"location":"equipment/","text":"Hardware Requirements for Linux and the RICOH THETA Jetson Nano - Reference Platform Our reference platform is the NVIDIA Jetson Nano, ref . We are using B01, but A02 should also work. running JetPack 4.4, which is Ubuntu 18.04. The Nano is an ARM A57 with a 128-core Maxwell GPU, 4GB 64-bit LPDDR4. The nano is powered by a 5V 4A barrel connector, not the microUSB which is 5V 2A. Our Nano has an external fan on the PWM header and a 64GB microSD card. Parts NVIDIA Jetson Nano Developer Kit B01 SMAKIN DC 5V/4A power supply with barrel connector Waveshare 5V PWM fan - cheaper option - we used this one as we are frugal. It worked. Noctua 5V PWM fan - better option, around $15 - most people use this one. For Z1 streaming 10' USB-C live streaming cable - it works for me, but it is over the recommended length. I only have the long cable for convenience. You should use as short a cable as possible. x86 Linux We've also tested the libuvc-theta (streaming) and libuvc-theta-sample (streaming sample application) on x86 64bit Linux using Ubuntu 20.04 LTS, Focal Fossa. We've tested v4l2loopback with gst_loopback on a low-end Pentium x86 computer. It works fine. Thanks to commuity member Yu You for this fix to gst_view.c. Note the addition of qos=false to the pipeline. This is currently on line 190 . if (strcmp(cmd_name, \"gst_loopback\") == 0) pipe_proc = \"decodebin ! autovideoconvert ! \" \"video/x-raw,format=I420 ! identity drop-allocation=true !\" \"v4l2sink device=/dev/video0 qos=false sync=false\"; Screenshot of loopback running on /dev/video0 , tested with vlc. Addtional x86 Information If you're having problems after making the modification described above, you can try to temporarily disable your dedicated graphics card on x86. In our tests on Ubuntu 20, Focal Fossa, the gstreamer vaapi plugin can't use the hardware decoder on the NVIDIA GPU with the proprietary NVIDIA driver. The causes gstreamer to use a software decoder instead. This will likely cause many frame drops on your system. You can verify this by setting the GST_DEBUG environment variable to 2 or 3 and then running gst_loopback. You will likely see many frame drop messages. There are two possible workarounds: Use the nvdec plugin Although the nvdec plugin is a part of the gstreamer-plugins-bad, it is not included in binary distribution due to license problem. Thus, you have to build the plugin by yourself. You also need to modify the pipeline of the gst_loopback accordingly. Use hardware decoder on the iGPU You may need additional setup to run X server on the iGPU, Raspberry Pi The Raspberry Pi will work great with the USB API. However, you will not have a good experience streaming 4K, even with the Raspberry Pi 4. The Raspberry Pi's H.264 hardware decoder does not support 4K resolution even on the Raspberry Pi4. In addition, older Pis' (Pi to Pi3) memory bandwidth(32bit DDR2) is too poor to handle even FHD stream from THETA V/Z1. NVIDIA Jetson Xavier The Xavier is better for testing. However, it is more expensive. If your budget permits, it is better to get the Xavier. You may have problems with 4K AI processing with the Nano. On Jetson Xavier, auto plugin selection of the gstreamer seems to be not working well, replacing \"decodebin ! autovideosink sync=false\" to \"nvv4l2decoder ! nv3dsink sync=false\" will solve the problem. Edit this line in the sample code and recompile. Heat and Cooling of Linux Computer You need to cool the Nano. Without a fan, you may get thermal throttling when live streaming with AI processing. The fan is 5V pwm. I've also used a 12V fan before I ordered the 4V fan from Amazon.","title":"Equipment"},{"location":"equipment/#hardware-requirements-for-linux-and-the-ricoh-theta","text":"","title":"Hardware Requirements for Linux and the RICOH THETA"},{"location":"equipment/#jetson-nano-reference-platform","text":"Our reference platform is the NVIDIA Jetson Nano, ref . We are using B01, but A02 should also work. running JetPack 4.4, which is Ubuntu 18.04. The Nano is an ARM A57 with a 128-core Maxwell GPU, 4GB 64-bit LPDDR4. The nano is powered by a 5V 4A barrel connector, not the microUSB which is 5V 2A. Our Nano has an external fan on the PWM header and a 64GB microSD card.","title":"Jetson Nano - Reference Platform"},{"location":"equipment/#parts","text":"NVIDIA Jetson Nano Developer Kit B01 SMAKIN DC 5V/4A power supply with barrel connector Waveshare 5V PWM fan - cheaper option - we used this one as we are frugal. It worked. Noctua 5V PWM fan - better option, around $15 - most people use this one. For Z1 streaming 10' USB-C live streaming cable - it works for me, but it is over the recommended length. I only have the long cable for convenience. You should use as short a cable as possible.","title":"Parts"},{"location":"equipment/#x86-linux","text":"We've also tested the libuvc-theta (streaming) and libuvc-theta-sample (streaming sample application) on x86 64bit Linux using Ubuntu 20.04 LTS, Focal Fossa. We've tested v4l2loopback with gst_loopback on a low-end Pentium x86 computer. It works fine. Thanks to commuity member Yu You for this fix to gst_view.c. Note the addition of qos=false to the pipeline. This is currently on line 190 . if (strcmp(cmd_name, \"gst_loopback\") == 0) pipe_proc = \"decodebin ! autovideoconvert ! \" \"video/x-raw,format=I420 ! identity drop-allocation=true !\" \"v4l2sink device=/dev/video0 qos=false sync=false\"; Screenshot of loopback running on /dev/video0 , tested with vlc.","title":"x86 Linux"},{"location":"equipment/#addtional-x86-information","text":"If you're having problems after making the modification described above, you can try to temporarily disable your dedicated graphics card on x86. In our tests on Ubuntu 20, Focal Fossa, the gstreamer vaapi plugin can't use the hardware decoder on the NVIDIA GPU with the proprietary NVIDIA driver. The causes gstreamer to use a software decoder instead. This will likely cause many frame drops on your system. You can verify this by setting the GST_DEBUG environment variable to 2 or 3 and then running gst_loopback. You will likely see many frame drop messages. There are two possible workarounds: Use the nvdec plugin Although the nvdec plugin is a part of the gstreamer-plugins-bad, it is not included in binary distribution due to license problem. Thus, you have to build the plugin by yourself. You also need to modify the pipeline of the gst_loopback accordingly. Use hardware decoder on the iGPU You may need additional setup to run X server on the iGPU,","title":"Addtional x86 Information"},{"location":"equipment/#raspberry-pi","text":"The Raspberry Pi will work great with the USB API. However, you will not have a good experience streaming 4K, even with the Raspberry Pi 4. The Raspberry Pi's H.264 hardware decoder does not support 4K resolution even on the Raspberry Pi4. In addition, older Pis' (Pi to Pi3) memory bandwidth(32bit DDR2) is too poor to handle even FHD stream from THETA V/Z1.","title":"Raspberry Pi"},{"location":"equipment/#nvidia-jetson-xavier","text":"The Xavier is better for testing. However, it is more expensive. If your budget permits, it is better to get the Xavier. You may have problems with 4K AI processing with the Nano. On Jetson Xavier, auto plugin selection of the gstreamer seems to be not working well, replacing \"decodebin ! autovideosink sync=false\" to \"nvv4l2decoder ! nv3dsink sync=false\" will solve the problem. Edit this line in the sample code and recompile.","title":"NVIDIA Jetson Xavier"},{"location":"equipment/#heat-and-cooling-of-linux-computer","text":"You need to cool the Nano. Without a fan, you may get thermal throttling when live streaming with AI processing. The fan is 5V pwm. I've also used a 12V fan before I ordered the 4V fan from Amazon.","title":"Heat and Cooling of Linux Computer"},{"location":"help/","text":"Getting Help Updated Docs and Events Community discussion - Linux Streaming Community discussion - USB API If you want to talk to someone, send email to jcasman@oppkey.com FAQ Can I stream indefinitely? The THETA Z1 can power off the USB-C port and stream at the same time. Using USB 3.0 or better, the charge increases in our tests. The camera does get hot. Upgrade to the latest firmware. If possible, attach a small fan to your tripod and point it at the body of the THETA. The V drains slowly. It will last about 8 hours. You may be able to bypass the battery, but this is not tested. /dev/video0 freezes on x86 Change line 190 of gst_viewer.c. if (strcmp(cmd_name, \"gst_loopback\") == 0) pipe_proc = \"decodebin ! autovideoconvert ! \" \"video/x-raw,format=I420 ! identity drop-allocation=true !\" \"v4l2sink device=/dev/video0 qos=false sync=false\"; The THETA is not appearing on /dev/video0 Install v4l2loopback . How do I reduce the default 4K stream to 2K to improve AI processing? If your AI processing is going to slowly, try to reduce resolution from 4K to 2K. You likely need to do this on Jetson Nano as 4K often hangs due to limited resources on Nano. In gst_viewer.c, change line 248 from THETAUVC_MODE_UHD_2997 to THETAUVC_MODE_FHD_2997. Refer to thetauvc.c#L55 for definition. I can't use it on Xavier Change to: \"nvv4l2decoder ! nv3dsink sync=false\"","title":"Help"},{"location":"help/#getting-help","text":"Updated Docs and Events Community discussion - Linux Streaming Community discussion - USB API If you want to talk to someone, send email to jcasman@oppkey.com","title":"Getting Help"},{"location":"help/#faq","text":"","title":"FAQ"},{"location":"help/#can-i-stream-indefinitely","text":"The THETA Z1 can power off the USB-C port and stream at the same time. Using USB 3.0 or better, the charge increases in our tests. The camera does get hot. Upgrade to the latest firmware. If possible, attach a small fan to your tripod and point it at the body of the THETA. The V drains slowly. It will last about 8 hours. You may be able to bypass the battery, but this is not tested.","title":"Can I stream indefinitely?"},{"location":"help/#devvideo0-freezes-on-x86","text":"Change line 190 of gst_viewer.c. if (strcmp(cmd_name, \"gst_loopback\") == 0) pipe_proc = \"decodebin ! autovideoconvert ! \" \"video/x-raw,format=I420 ! identity drop-allocation=true !\" \"v4l2sink device=/dev/video0 qos=false sync=false\";","title":"/dev/video0 freezes on x86"},{"location":"help/#the-theta-is-not-appearing-on-devvideo0","text":"Install v4l2loopback .","title":"The THETA is not appearing on /dev/video0"},{"location":"help/#how-do-i-reduce-the-default-4k-stream-to-2k-to-improve-ai-processing","text":"If your AI processing is going to slowly, try to reduce resolution from 4K to 2K. You likely need to do this on Jetson Nano as 4K often hangs due to limited resources on Nano. In gst_viewer.c, change line 248 from THETAUVC_MODE_UHD_2997 to THETAUVC_MODE_FHD_2997. Refer to thetauvc.c#L55 for definition.","title":"How do I reduce the default 4K stream to 2K to improve AI processing?"},{"location":"help/#i-cant-use-it-on-xavier","text":"Change to: \"nvv4l2decoder ! nv3dsink sync=false\"","title":"I can't use it on Xavier"},{"location":"meetup/","text":"Notes Archive September 1, 2020 - First Linux Meetup","title":"Meetup Archive"},{"location":"meetup/#notes-archive","text":"September 1, 2020 - First Linux Meetup","title":"Notes Archive"},{"location":"software/","text":"Software Requirements Live Streaming You need to download the two GitHub repos below and compile the driver and sample code. libuvc-theta libuvc-theta-sample If you want to use /dev/video0 , you will also need v4l2loopback In addition, there are numerous dependencies to compile the tools listed above. However, have no fear, we will walk you through it. How To Compile and Install Build and install on x86 Ubuntu 20.04 Jetson Nano with OpenCV and VLC on /dev/video0 Compile libuvc-theta on Jetson Nano - silent screencast Build and run v4l2loopback on Jetson Nano . Needed for /dev/video0 How to Load v4l2loopback automatically In the file /etc/modules-load.d/modules.conf add a new line v4l2loopback . $ pwd /etc/modules-load.d craig@jetson:/etc/modules-load.d$ cat modules.conf # /etc/modules: kernel modules to load at boot time. # # This file contains the names of kernel modules that should be loaded # at boot time, one per line. Lines beginning with \"#\" are ignored. # bluedroid_pm, supporting module for bluetooth bluedroid_pm # modules for camera HAL nvhost_vi # nvgpu module nvgpu # for RICOH THETA live streaming # v4l2loopback device on /dev/video0. specify in gst_viewer.c v4l2loopback craig@jetson:/etc/modules-load.d$ Check kernel module load $ lsmod Module Size Used by bnep 16562 2 zram 26166 4 overlay 48691 0 spidev 13282 0 v4l2loopback 37383 0 nvgpu 1579891 18 bluedroid_pm 13912 0 ip_tables 19441 0 x_tables 28951 1 ip_tables craig@jetson:/etc/modules-load.d$ USB API libptp - next section for detailed walkthrough","title":"Software"},{"location":"software/#software-requirements","text":"","title":"Software Requirements"},{"location":"software/#live-streaming","text":"You need to download the two GitHub repos below and compile the driver and sample code. libuvc-theta libuvc-theta-sample If you want to use /dev/video0 , you will also need v4l2loopback In addition, there are numerous dependencies to compile the tools listed above. However, have no fear, we will walk you through it.","title":"Live Streaming"},{"location":"software/#how-to-compile-and-install","text":"Build and install on x86 Ubuntu 20.04 Jetson Nano with OpenCV and VLC on /dev/video0 Compile libuvc-theta on Jetson Nano - silent screencast Build and run v4l2loopback on Jetson Nano . Needed for /dev/video0","title":"How To Compile and Install"},{"location":"software/#how-to-load-v4l2loopback-automatically","text":"In the file /etc/modules-load.d/modules.conf add a new line v4l2loopback . $ pwd /etc/modules-load.d craig@jetson:/etc/modules-load.d$ cat modules.conf # /etc/modules: kernel modules to load at boot time. # # This file contains the names of kernel modules that should be loaded # at boot time, one per line. Lines beginning with \"#\" are ignored. # bluedroid_pm, supporting module for bluetooth bluedroid_pm # modules for camera HAL nvhost_vi # nvgpu module nvgpu # for RICOH THETA live streaming # v4l2loopback device on /dev/video0. specify in gst_viewer.c v4l2loopback craig@jetson:/etc/modules-load.d$","title":"How to Load v4l2loopback automatically"},{"location":"software/#check-kernel-module-load","text":"$ lsmod Module Size Used by bnep 16562 2 zram 26166 4 overlay 48691 0 spidev 13282 0 v4l2loopback 37383 0 nvgpu 1579891 18 bluedroid_pm 13912 0 ip_tables 19441 0 x_tables 28951 1 ip_tables craig@jetson:/etc/modules-load.d$","title":"Check kernel module load"},{"location":"software/#usb-api","text":"libptp - next section for detailed walkthrough","title":"USB API"},{"location":"usb_api/","text":"This document covers two different strategies: libptp - either as library or with command line ptpcam gphoto2 - command line and Python bindings to library Setup libptp Download libptp source libptp - Picture Transfer Protocol lib Get the newest version, which is 2-1.2 right now. build libptp $ ./configure $ make If you have a build error when compiling libusb, you may need to install the development libraries for libusb. install libusb-dev $ sudo apt install libusb-dev You may not need this step if you already have the libusb development libraries installed. Example on x86 Ubuntu 20.04. $ sudo apt-get install libusb-dev install libptp $ sudo make install On x86 Ubuntu 20.04. $ tar zxvf libptp2-1.2.0.tar.gz libptp2-1.2.0/ ./configure ran with no problems make ran with no problems sudo make install ran with no problems $ pwd /usr/local/lib $ ls -l libptp2.* -rw-r--r-- 1 root root 352640 Aug 31 11:54 libptp2.a -rwxr-xr-x 1 root root 941 Aug 31 11:54 libptp2.la lrwxrwxrwx 1 root root 16 Aug 31 11:54 libptp2.so -> libptp2.so.1.1.5 lrwxrwxrwx 1 root root 16 Aug 31 11:54 libptp2.so.1 -> libptp2.so.1.1.5 -rwxr-xr-x 1 root root 249352 Aug 31 11:54 libptp2.so.1.1.5 set /usr/local/lib in library path The default location of the libptp install is /usr/local/lib . Make sure that this is in your library path. If it isn't, add it to a file such as libc.conf in /etc/ld.so.conf/ . $ cd /etc/ld.so.conf.d/ $ ls $ cat libc.conf run ldconfig Load the library configuration. $ sudo /sbin/ldconfig -v On x86 Ubuntu 20.04. $ cd /etc/ld.so.conf.d/ $ l fakeroot-x86_64-linux-gnu.conf x86_64-linux-gnu.conf i386-linux-gnu.conf zz_i386-biarch-compat.conf libc.conf $ cat libc.conf # libc default configuration /usr/local/lib $ sudo ldconfig $ Test ptpcam Connect RICOH THETA to Jetson with a USB cable. Version of 2-1.2 of libptp has a bug in it. Although ptpcam does take pictures and function normally, you will see an error about capture status. On x86 Ubuntu. $ ptpcam --info Camera information ================== Model: RICOH THETA Z1 manufacturer: Ricoh Company, Ltd. serial number: '10010104' device version: 1.50.1 extension ID: 0x00000006 extension description: (null) extension version: 0x006e $ cat /proc/cpuinfo processor : 0 vendor_id : GenuineIntel cpu family : 6 model : 60 model name : Intel(R) Pentium(R) CPU G3258 @ 3.20GHz Fix problem with libptp response Go to line 77 of ptp.h and change PTP_USB_INT_PACKET_LEN to 28 . After modification, the code will look like this. Using USB API with ptpcam (libptp) test ptpcam response again Take a still image picture with ptpcam --capture . Set camera to live streaming mode Check on camera mode. $ ptpcam --show-property=0x5013 Set to live streaming mode. $ ptpcam --set-property=0x5013 --val=0x8005 Using the official RICOH USB API documentation , you can verify that 0x8005 is live streaming mode. The camera LED should show that the THETA is in LIVE mode. In our tests, the RICOH THETA Z1 could charge while streaming over a USB 3.0 port (blue insert). After hours of streaming, the Z1 LED looks like this. The response codes are shown below. 0x0001 = single-shot shooting 0x0003 = Interval shooting 0x8002 = Movie shooting 0x8003 = Interval composite shooting 0x8004 = Multi bracket shooting 0x8005 = Live streaming 0x8006 = Interval shooting - tripod stabilizatio is off (top/bottom correction and stitching optimized) 0x8007 = Interval shooting - tripod stabilization is on If you set the camera back to still image, single shot mode, you will see this response. $ ptpcam --set-property=0x5013 --val=0x0001 Camera: RICOH THETA V 'Still Capture Mode' is set to: 0x8005 (-32763) Changing property value to 0x0001 [(null)] succeeded. Wake Camera From Sleep In this test, I have the Z1 power off disabled. I left the camera in sleep mode overnight. When I woke up in the morning, I woke the Z1 up using an ssh session into the Jetson Nano and running this command. $ ptpcam --set-property=0xD80E --val=0x00 Camera: RICOH THETA Z1 'UNKNOWN' is set to: 1 Changing property value to 0x00 [(null)] succeeded. I tested the camera with the info command. $ ptpcam --info Camera information ================== Model: RICOH THETA Z1 manufacturer: Ricoh Company, Ltd. serial number: '10010104' device version: 1.50.1 extension ID: 0x00000006 extension description: (null) extension version: 0x006e In my initial tests, I had to run the info command twice after I woke the camera up from sleep. The first time, I could not open the session. I got this error. $ ptpcam --info ERROR: Could not open session! In the future, I'll run more tests using the camera FunctionalMode to check status. This is another example with x86. Initially, the camera is asleep. craig@cube:~$ ptpcam --info Camera information ================== ERROR: Could not open session! craig@cube:~$ ptpcam --info Camera information ================== Model: RICOH THETA Z1 manufacturer: Ricoh Company, Ltd. serial number: '10010104' device version: 1.50.1 extension ID: 0x00000006 extension description: (null) extension version: 0x006e craig@cube:~$ ptpcam --set-property=0xd80e --val=0 Camera: RICOH THETA Z1 'UNKNOWN' is set to: 1 Changing property value to 0 [(null)] succeeded. At this point, the camera is awake. Put camera to sleep $ ptpcam --set-property=0xd80e --val=0x01 Camera: RICOH THETA Z1 'UNKNOWN' is set to: 0 Changing property value to 0x01 [(null)] succeeded. The camera is asleep. Put Camera in Still Image Mode You may want to take a detailed picture of the scene based on triggers from the live stream. To do this, you need to take the camera out of live streaming mode and put it into still image mode. In the example below, I wrapped ptpcam in a script that explains the hexcode properties of the mode settings. This helps me with testing. $ ptpcam --set-property=0x5013 --val=0x0001 Camera: RICOH THETA Z1 'Still Capture Mode' is set to: [Normal] Changing property value to 0x0001 [(null)] succeeded. 0x0001 = single-shot shooting 0x0003 = Interval shooting 0x8002 = Movie shooting 0x8003 = Interval composite shooting 0x8004 = Multi bracket shooting 0x8005 = Live streaming 0x8006 = Interval shooting - tripod stabilizatio is off (top/bottom correction and stitching optimized) 0x8007 = Interval shooting - tripod stabilization is on You can verify the mode of with 0x5013. $ ptpcam --show-property=0x5013 Camera: RICOH THETA Z1 'Still Capture Mode' is set to: [Normal] Compare this with the result when the camera is in live streaming mode. $ ptpcam --show-property=0x5013 Camera: RICOH THETA Z1 'Still Capture Mode' is set to: 0x8005 (-32763) 0x0001 = single-shot shooting 0x0003 = Interval shooting 0x8002 = Movie shooting 0x8003 = Interval composite shooting 0x8004 = Multi bracket shooting 0x8005 = Live streaming 0x8006 = Interval shooting - tripod stabilizatio is off (top/bottom correction and stitching optimized) 0x8007 = Interval shooting - tripod stabilization is on Start Video Capture This records video to file. ptpcam -R 0x101c,0,0,1 gphoto2 Command Line Fixing Command Line Error - Could not claim the USB device You may get this error. $ gphoto2 --capture-image *** Error *** An error occurred in the io-library ('Could not claim the USB device'): Could not claim interface 0 (Device or resource busy). Make sure no other program (gvfs-gphoto2-volume-monitor) or kernel module (such as sdc2xx, stv680, spca50x) is using the device and you have read/write access to the device. ERROR: Could not capture image. ERROR: Could not capture. *** Error (-53: 'Could not claim the USB device') *** Fix for current session is to kill gvfs-gphoto2-volume-monitor and gvfsd-gphoto2 spawner. $ ps aux |grep gvfs ... craig 2422 0.0 0.0 442504 13528 ? Sl 08:19 0:00 /usr/libexec/gvfsd-gphoto2 --spawner :1.3 /org/gtk/gvfs/exec_spaw/1 ... craig 1969 0.0 0.0 249860 10032 ? Ssl 08:19 0:00 /usr/libexec/gvfs-gphoto2-volume-monitor ... $ kill 2422 $ kill 1969 $ gphoto2 --capture-image New file is in location /store_00020001/DCIM/100RICOH/R0010376.JPG on the camera $ Removing gvfs-backend permanently If you don't mount the THETA as a storage device with gphoto, you can remove gvfs-backend. This is a workaround for the conflict when you use gphoto2 from the command line to talk to the THETA. $ sudo apt remove gvfs-backends [sudo] password for craig: Reading package lists... Done Building dependency tree Reboot to test. After reboot. $ gphoto2 -l There is 1 folder in folder '/'. - store_00020001 There is 1 folder in folder '/store_00020001'. - DCIM There are 2 folders in folder '/store_00020001/DCIM'. - 100RICOH - SingleLensShooting There is 1 folder in folder '/store_00020001/DCIM/100RICOH'. - HDR07-22_18-13 There are 0 folders in folder '/store_00020001/DCIM/100RICOH/HDR07-22_18-13'. There are 0 folders in folder '/store_00020001/DCIM/SingleLensShooting'. It works! Check Camera Mode (still image, video, streaming) StillCaptureMode API reference $ gphoto2 --get-config=5013 Label: Still Capture Mode Readonly: 0 Type: MENU Current: 1 Choice: 0 1 Choice: 1 3 Choice: 2 32770 Choice: 3 32771 Choice: 4 32772 Choice: 5 32773 Choice: 6 32774 Choice: 7 32775 END craig@craig-desktop:~$ set to video mode Using the API reference , we can see that video mode is hex 0x8002 or 32770 in base 10. $ gphoto2 --set-config=5013=32770 Python bindings From community member mhenrie original post \"\"\" USB api for added performance over http Theta api reference: https://developers.theta360.com/en/docs/v2/usb_reference/ Unable to get mtp or ptp to connect to the camera; After some pain was able to get gphoto2 working \"\"\" import os import time import gphoto2 as gp # Properties SHUTTER_SPEED = 'd00f' EXPOSURE_INDEX = '500f' F_NUMBER = '5007' AUDIO_VOLUME = '502c' COLOR_TEMPERATURE = 'd813' EXPOSURE_PROGRAM_MODE = '500e' # milliseconds TIMEOUT = 10 TIMEOUT_CAPTURE_DNG = 10000 def wait_for_event(camera, timeout=TIMEOUT, event_type=gp.GP_EVENT_TIMEOUT): \"\"\" Wait for event_type to to be triggered. :param camera: :param timeout: :param event_type: :return: event_data \"\"\" while True: _event_type, event_data = camera.wait_for_event(timeout) if _event_type == gp.GP_EVENT_TIMEOUT: return if _event_type == event_type: return event_data def set_config_by_index(config, index): \"\"\"Set config using choice index\"\"\" value = config.get_choice(index) config.set_value(value) return config # def list_files(camera, path='/'): # result = [] # # get files # for name, value in camera.folder_list_files(path): # result.append(os.path.join(path, name)) # # read folders # folders = [] # for name, value in camera.folder_list_folders(path): # folders.append(name) # # recurse over subfolders # for name in folders: # result.extend(list_files(camera, os.path.join(path, name))) # return result # # # def get_file_info(camera, path): # folder, name = os.path.split(path) # return camera.file_get_info(folder, name) class CameraUsb(object): \"\"\" Define API for multiple exposure \"\"\" def __init__(self, verbose=False): self.verbose = verbose self.camera = gp.Camera() self.camera_config = None self.status_config = None self.other_config = None self.shutter_speed_config = None self.shutter_speed_options = [] def init(self): \"\"\" Set manual exposure and other defaults :return: config \"\"\" try: self.camera_config = self.camera.get_config() except gp.GPhoto2Error: raise RuntimeError(\"Unable to connect to Camera\") self.other_config = self.camera_config.get_child_by_name('other') # Manual/f-stop/iso exposure_program_mode = self.other_config.get_child_by_name(EXPOSURE_PROGRAM_MODE) if not exposure_program_mode.get_value() == '1': print('Setting camera to Manual exposure program') exposure_program_mode.set_value('1') self.camera.set_config(self.camera_config) wait_for_event(self.camera) # When switching exposure program, we need to refresh the configs self.camera_config = self.camera.get_config() self.other_config = self.camera_config.get_child_by_name('other') self.status_config = self.camera_config.get_child_by_name('status') self.shutter_speed_config = self.other_config.get_child_by_name(SHUTTER_SPEED) self.shutter_speed_options = [str(x) for x in self.shutter_speed_config.get_choices()] if len(self.shutter_speed_options) != 61: raise RuntimeError('Unble to determine shutter speed options; restart app') fstop = self.other_config.get_child_by_name(F_NUMBER) fstop.set_value('560') iso = self.other_config.get_child_by_name(EXPOSURE_INDEX) iso.set_value('80') self.camera.set_config(self.camera_config) wait_for_event(self.camera) def get_info(self): \"\"\" :return: Dict containing serialnumber, batterylevel, remainingpictures, etc \"\"\" if not self.camera_config: self.init() battery_level = self.status_config.get_child_by_name('batterylevel').get_value() # Convert '67%' to int battery_level = int(''.join([x for x in battery_level if x.isdigit()])) info = {'serialnumber': self.status_config.get_child_by_name('serialnumber').get_value(), 'cameramodel': self.status_config.get_child_by_name('cameramodel').get_value(), 'deviceversion': self.status_config.get_child_by_name('deviceversion').get_value(), 'batterylevel': battery_level, 'remainingpictures': int(self.camera.get_storageinfo()[0].freeimages)} return info def take_picture(self, shutter_speed_index=None, color_temperature=None, volume=None): \"\"\" Set camera options and take picture Blocking :param shutter_speed_index: int in range 0-60 (0 fastest shutter) :param color_temperature: in in range 2500-10000 by 100 increment :param volume: int in range 0-100 :return: (jpg_path, dng_path) \"\"\" t1 = time.time() if not self.camera_config: self.init() if shutter_speed_index is not None: self.shutter_speed_config.set_value(self.shutter_speed_options[shutter_speed_index]) if color_temperature is not None: self.other_config.get_child_by_name(COLOR_TEMPERATURE).set_value(color_temperature) if volume is not None: self.other_config.get_child_by_name(AUDIO_VOLUME).set_value(str(volume)) self.camera.set_config(self.camera_config) # We need this even though no event is triggered wait_for_event(self.camera) gp_jpg_path = self.camera.capture(gp.GP_CAPTURE_IMAGE) gp_dng_path = wait_for_event(self.camera, timeout=TIMEOUT_CAPTURE_DNG, event_type=gp.GP_EVENT_FILE_ADDED) if not gp_dng_path: raise RuntimeError('Unable to copy DNG') jpg_path = os.path.join(gp_jpg_path.folder, gp_jpg_path.name) dng_path = os.path.join(gp_dng_path.folder, gp_dng_path.name) print('Capture took %0.03f sec' % (time.time() - t1, )) return jpg_path, dng_path def download_file(self, src_path, dst_path, delete=True): \"\"\"Copy the file from the camera src_path to local dst_path\"\"\" t1 = time.time() src_folder, src_name = os.path.split(src_path) src_file = self.camera.file_get(src_folder, src_name, gp.GP_FILE_TYPE_NORMAL) print('Download %s ->\\n\\t%s' % (src_path, dst_path)) src_file.save(dst_path) wait_for_event(self.camera) print('Download took %0.03f sec' % (time.time() - t1, )) if delete: t1 = time.time() print('Delete %s' % src_path) self.camera.file_delete(src_folder, src_name) wait_for_event(self.camera) print('Delete took %0.03f sec' % (time.time() - t1, )) def _unittest(): \"\"\"test a short exposure sequence\"\"\" # temporary directory dst_template = '/tmp/theta/capture.%04d.%s' t1 = time.time() camera = CameraUsb() camera.init() print(camera.get_info()) frame = 1 jpg_path, dng_path = camera.take_picture(0) print(jpg_path, dng_path) camera.download_file(dng_path, dst_template % (frame, 'dng')) frame += 1 jpg_path, dng_path = camera.take_picture(24) print(jpg_path, dng_path) camera.download_file(dng_path, dst_template % (frame, 'dng')) frame += 1 jpg_path, dng_path = camera.take_picture(42) print(jpg_path, dng_path) camera.download_file(dng_path, dst_template % (frame, 'dng')) frame += 1 print('Done in %0.03f sec' % (time.time() - t1, )) if __name__ == \"__main__\": _unittest()","title":"USB API"},{"location":"usb_api/#setup-libptp","text":"","title":"Setup libptp"},{"location":"usb_api/#download-libptp-source","text":"libptp - Picture Transfer Protocol lib Get the newest version, which is 2-1.2 right now.","title":"Download libptp source"},{"location":"usb_api/#build-libptp","text":"$ ./configure $ make If you have a build error when compiling libusb, you may need to install the development libraries for libusb.","title":"build libptp"},{"location":"usb_api/#install-libusb-dev","text":"$ sudo apt install libusb-dev You may not need this step if you already have the libusb development libraries installed. Example on x86 Ubuntu 20.04. $ sudo apt-get install libusb-dev","title":"install libusb-dev"},{"location":"usb_api/#install-libptp","text":"$ sudo make install On x86 Ubuntu 20.04. $ tar zxvf libptp2-1.2.0.tar.gz libptp2-1.2.0/ ./configure ran with no problems make ran with no problems sudo make install ran with no problems $ pwd /usr/local/lib $ ls -l libptp2.* -rw-r--r-- 1 root root 352640 Aug 31 11:54 libptp2.a -rwxr-xr-x 1 root root 941 Aug 31 11:54 libptp2.la lrwxrwxrwx 1 root root 16 Aug 31 11:54 libptp2.so -> libptp2.so.1.1.5 lrwxrwxrwx 1 root root 16 Aug 31 11:54 libptp2.so.1 -> libptp2.so.1.1.5 -rwxr-xr-x 1 root root 249352 Aug 31 11:54 libptp2.so.1.1.5","title":"install libptp"},{"location":"usb_api/#set-usrlocallib-in-library-path","text":"The default location of the libptp install is /usr/local/lib . Make sure that this is in your library path. If it isn't, add it to a file such as libc.conf in /etc/ld.so.conf/ . $ cd /etc/ld.so.conf.d/ $ ls $ cat libc.conf","title":"set /usr/local/lib in library path"},{"location":"usb_api/#run-ldconfig","text":"Load the library configuration. $ sudo /sbin/ldconfig -v On x86 Ubuntu 20.04. $ cd /etc/ld.so.conf.d/ $ l fakeroot-x86_64-linux-gnu.conf x86_64-linux-gnu.conf i386-linux-gnu.conf zz_i386-biarch-compat.conf libc.conf $ cat libc.conf # libc default configuration /usr/local/lib $ sudo ldconfig $","title":"run ldconfig"},{"location":"usb_api/#test-ptpcam","text":"Connect RICOH THETA to Jetson with a USB cable. Version of 2-1.2 of libptp has a bug in it. Although ptpcam does take pictures and function normally, you will see an error about capture status. On x86 Ubuntu. $ ptpcam --info Camera information ================== Model: RICOH THETA Z1 manufacturer: Ricoh Company, Ltd. serial number: '10010104' device version: 1.50.1 extension ID: 0x00000006 extension description: (null) extension version: 0x006e $ cat /proc/cpuinfo processor : 0 vendor_id : GenuineIntel cpu family : 6 model : 60 model name : Intel(R) Pentium(R) CPU G3258 @ 3.20GHz","title":"Test ptpcam"},{"location":"usb_api/#fix-problem-with-libptp-response","text":"Go to line 77 of ptp.h and change PTP_USB_INT_PACKET_LEN to 28 . After modification, the code will look like this.","title":"Fix problem with libptp response"},{"location":"usb_api/#using-usb-api-with-ptpcam-libptp","text":"","title":"Using USB API with ptpcam (libptp)"},{"location":"usb_api/#test-ptpcam-response-again","text":"Take a still image picture with ptpcam --capture .","title":"test ptpcam response again"},{"location":"usb_api/#set-camera-to-live-streaming-mode","text":"Check on camera mode. $ ptpcam --show-property=0x5013 Set to live streaming mode. $ ptpcam --set-property=0x5013 --val=0x8005 Using the official RICOH USB API documentation , you can verify that 0x8005 is live streaming mode. The camera LED should show that the THETA is in LIVE mode. In our tests, the RICOH THETA Z1 could charge while streaming over a USB 3.0 port (blue insert). After hours of streaming, the Z1 LED looks like this. The response codes are shown below. 0x0001 = single-shot shooting 0x0003 = Interval shooting 0x8002 = Movie shooting 0x8003 = Interval composite shooting 0x8004 = Multi bracket shooting 0x8005 = Live streaming 0x8006 = Interval shooting - tripod stabilizatio is off (top/bottom correction and stitching optimized) 0x8007 = Interval shooting - tripod stabilization is on If you set the camera back to still image, single shot mode, you will see this response. $ ptpcam --set-property=0x5013 --val=0x0001 Camera: RICOH THETA V 'Still Capture Mode' is set to: 0x8005 (-32763) Changing property value to 0x0001 [(null)] succeeded.","title":"Set camera to live streaming mode"},{"location":"usb_api/#wake-camera-from-sleep","text":"In this test, I have the Z1 power off disabled. I left the camera in sleep mode overnight. When I woke up in the morning, I woke the Z1 up using an ssh session into the Jetson Nano and running this command. $ ptpcam --set-property=0xD80E --val=0x00 Camera: RICOH THETA Z1 'UNKNOWN' is set to: 1 Changing property value to 0x00 [(null)] succeeded. I tested the camera with the info command. $ ptpcam --info Camera information ================== Model: RICOH THETA Z1 manufacturer: Ricoh Company, Ltd. serial number: '10010104' device version: 1.50.1 extension ID: 0x00000006 extension description: (null) extension version: 0x006e In my initial tests, I had to run the info command twice after I woke the camera up from sleep. The first time, I could not open the session. I got this error. $ ptpcam --info ERROR: Could not open session! In the future, I'll run more tests using the camera FunctionalMode to check status. This is another example with x86. Initially, the camera is asleep. craig@cube:~$ ptpcam --info Camera information ================== ERROR: Could not open session! craig@cube:~$ ptpcam --info Camera information ================== Model: RICOH THETA Z1 manufacturer: Ricoh Company, Ltd. serial number: '10010104' device version: 1.50.1 extension ID: 0x00000006 extension description: (null) extension version: 0x006e craig@cube:~$ ptpcam --set-property=0xd80e --val=0 Camera: RICOH THETA Z1 'UNKNOWN' is set to: 1 Changing property value to 0 [(null)] succeeded. At this point, the camera is awake.","title":"Wake Camera From Sleep"},{"location":"usb_api/#put-camera-to-sleep","text":"$ ptpcam --set-property=0xd80e --val=0x01 Camera: RICOH THETA Z1 'UNKNOWN' is set to: 0 Changing property value to 0x01 [(null)] succeeded. The camera is asleep.","title":"Put camera to sleep"},{"location":"usb_api/#put-camera-in-still-image-mode","text":"You may want to take a detailed picture of the scene based on triggers from the live stream. To do this, you need to take the camera out of live streaming mode and put it into still image mode. In the example below, I wrapped ptpcam in a script that explains the hexcode properties of the mode settings. This helps me with testing. $ ptpcam --set-property=0x5013 --val=0x0001 Camera: RICOH THETA Z1 'Still Capture Mode' is set to: [Normal] Changing property value to 0x0001 [(null)] succeeded. 0x0001 = single-shot shooting 0x0003 = Interval shooting 0x8002 = Movie shooting 0x8003 = Interval composite shooting 0x8004 = Multi bracket shooting 0x8005 = Live streaming 0x8006 = Interval shooting - tripod stabilizatio is off (top/bottom correction and stitching optimized) 0x8007 = Interval shooting - tripod stabilization is on You can verify the mode of with 0x5013. $ ptpcam --show-property=0x5013 Camera: RICOH THETA Z1 'Still Capture Mode' is set to: [Normal] Compare this with the result when the camera is in live streaming mode. $ ptpcam --show-property=0x5013 Camera: RICOH THETA Z1 'Still Capture Mode' is set to: 0x8005 (-32763) 0x0001 = single-shot shooting 0x0003 = Interval shooting 0x8002 = Movie shooting 0x8003 = Interval composite shooting 0x8004 = Multi bracket shooting 0x8005 = Live streaming 0x8006 = Interval shooting - tripod stabilizatio is off (top/bottom correction and stitching optimized) 0x8007 = Interval shooting - tripod stabilization is on","title":"Put Camera in Still Image Mode"},{"location":"usb_api/#start-video-capture","text":"This records video to file. ptpcam -R 0x101c,0,0,1","title":"Start Video Capture"},{"location":"usb_api/#gphoto2","text":"","title":"gphoto2"},{"location":"usb_api/#command-line","text":"","title":"Command Line"},{"location":"usb_api/#fixing-command-line-error-could-not-claim-the-usb-device","text":"You may get this error. $ gphoto2 --capture-image *** Error *** An error occurred in the io-library ('Could not claim the USB device'): Could not claim interface 0 (Device or resource busy). Make sure no other program (gvfs-gphoto2-volume-monitor) or kernel module (such as sdc2xx, stv680, spca50x) is using the device and you have read/write access to the device. ERROR: Could not capture image. ERROR: Could not capture. *** Error (-53: 'Could not claim the USB device') *** Fix for current session is to kill gvfs-gphoto2-volume-monitor and gvfsd-gphoto2 spawner. $ ps aux |grep gvfs ... craig 2422 0.0 0.0 442504 13528 ? Sl 08:19 0:00 /usr/libexec/gvfsd-gphoto2 --spawner :1.3 /org/gtk/gvfs/exec_spaw/1 ... craig 1969 0.0 0.0 249860 10032 ? Ssl 08:19 0:00 /usr/libexec/gvfs-gphoto2-volume-monitor ... $ kill 2422 $ kill 1969 $ gphoto2 --capture-image New file is in location /store_00020001/DCIM/100RICOH/R0010376.JPG on the camera $","title":"Fixing Command Line Error - Could not claim the USB device"},{"location":"usb_api/#removing-gvfs-backend-permanently","text":"If you don't mount the THETA as a storage device with gphoto, you can remove gvfs-backend. This is a workaround for the conflict when you use gphoto2 from the command line to talk to the THETA. $ sudo apt remove gvfs-backends [sudo] password for craig: Reading package lists... Done Building dependency tree Reboot to test. After reboot. $ gphoto2 -l There is 1 folder in folder '/'. - store_00020001 There is 1 folder in folder '/store_00020001'. - DCIM There are 2 folders in folder '/store_00020001/DCIM'. - 100RICOH - SingleLensShooting There is 1 folder in folder '/store_00020001/DCIM/100RICOH'. - HDR07-22_18-13 There are 0 folders in folder '/store_00020001/DCIM/100RICOH/HDR07-22_18-13'. There are 0 folders in folder '/store_00020001/DCIM/SingleLensShooting'. It works!","title":"Removing gvfs-backend permanently"},{"location":"usb_api/#check-camera-mode-still-image-video-streaming","text":"StillCaptureMode API reference $ gphoto2 --get-config=5013 Label: Still Capture Mode Readonly: 0 Type: MENU Current: 1 Choice: 0 1 Choice: 1 3 Choice: 2 32770 Choice: 3 32771 Choice: 4 32772 Choice: 5 32773 Choice: 6 32774 Choice: 7 32775 END craig@craig-desktop:~$","title":"Check Camera Mode (still image, video, streaming)"},{"location":"usb_api/#set-to-video-mode","text":"Using the API reference , we can see that video mode is hex 0x8002 or 32770 in base 10. $ gphoto2 --set-config=5013=32770","title":"set to video mode"},{"location":"usb_api/#python-bindings","text":"From community member mhenrie original post \"\"\" USB api for added performance over http Theta api reference: https://developers.theta360.com/en/docs/v2/usb_reference/ Unable to get mtp or ptp to connect to the camera; After some pain was able to get gphoto2 working \"\"\" import os import time import gphoto2 as gp # Properties SHUTTER_SPEED = 'd00f' EXPOSURE_INDEX = '500f' F_NUMBER = '5007' AUDIO_VOLUME = '502c' COLOR_TEMPERATURE = 'd813' EXPOSURE_PROGRAM_MODE = '500e' # milliseconds TIMEOUT = 10 TIMEOUT_CAPTURE_DNG = 10000 def wait_for_event(camera, timeout=TIMEOUT, event_type=gp.GP_EVENT_TIMEOUT): \"\"\" Wait for event_type to to be triggered. :param camera: :param timeout: :param event_type: :return: event_data \"\"\" while True: _event_type, event_data = camera.wait_for_event(timeout) if _event_type == gp.GP_EVENT_TIMEOUT: return if _event_type == event_type: return event_data def set_config_by_index(config, index): \"\"\"Set config using choice index\"\"\" value = config.get_choice(index) config.set_value(value) return config # def list_files(camera, path='/'): # result = [] # # get files # for name, value in camera.folder_list_files(path): # result.append(os.path.join(path, name)) # # read folders # folders = [] # for name, value in camera.folder_list_folders(path): # folders.append(name) # # recurse over subfolders # for name in folders: # result.extend(list_files(camera, os.path.join(path, name))) # return result # # # def get_file_info(camera, path): # folder, name = os.path.split(path) # return camera.file_get_info(folder, name) class CameraUsb(object): \"\"\" Define API for multiple exposure \"\"\" def __init__(self, verbose=False): self.verbose = verbose self.camera = gp.Camera() self.camera_config = None self.status_config = None self.other_config = None self.shutter_speed_config = None self.shutter_speed_options = [] def init(self): \"\"\" Set manual exposure and other defaults :return: config \"\"\" try: self.camera_config = self.camera.get_config() except gp.GPhoto2Error: raise RuntimeError(\"Unable to connect to Camera\") self.other_config = self.camera_config.get_child_by_name('other') # Manual/f-stop/iso exposure_program_mode = self.other_config.get_child_by_name(EXPOSURE_PROGRAM_MODE) if not exposure_program_mode.get_value() == '1': print('Setting camera to Manual exposure program') exposure_program_mode.set_value('1') self.camera.set_config(self.camera_config) wait_for_event(self.camera) # When switching exposure program, we need to refresh the configs self.camera_config = self.camera.get_config() self.other_config = self.camera_config.get_child_by_name('other') self.status_config = self.camera_config.get_child_by_name('status') self.shutter_speed_config = self.other_config.get_child_by_name(SHUTTER_SPEED) self.shutter_speed_options = [str(x) for x in self.shutter_speed_config.get_choices()] if len(self.shutter_speed_options) != 61: raise RuntimeError('Unble to determine shutter speed options; restart app') fstop = self.other_config.get_child_by_name(F_NUMBER) fstop.set_value('560') iso = self.other_config.get_child_by_name(EXPOSURE_INDEX) iso.set_value('80') self.camera.set_config(self.camera_config) wait_for_event(self.camera) def get_info(self): \"\"\" :return: Dict containing serialnumber, batterylevel, remainingpictures, etc \"\"\" if not self.camera_config: self.init() battery_level = self.status_config.get_child_by_name('batterylevel').get_value() # Convert '67%' to int battery_level = int(''.join([x for x in battery_level if x.isdigit()])) info = {'serialnumber': self.status_config.get_child_by_name('serialnumber').get_value(), 'cameramodel': self.status_config.get_child_by_name('cameramodel').get_value(), 'deviceversion': self.status_config.get_child_by_name('deviceversion').get_value(), 'batterylevel': battery_level, 'remainingpictures': int(self.camera.get_storageinfo()[0].freeimages)} return info def take_picture(self, shutter_speed_index=None, color_temperature=None, volume=None): \"\"\" Set camera options and take picture Blocking :param shutter_speed_index: int in range 0-60 (0 fastest shutter) :param color_temperature: in in range 2500-10000 by 100 increment :param volume: int in range 0-100 :return: (jpg_path, dng_path) \"\"\" t1 = time.time() if not self.camera_config: self.init() if shutter_speed_index is not None: self.shutter_speed_config.set_value(self.shutter_speed_options[shutter_speed_index]) if color_temperature is not None: self.other_config.get_child_by_name(COLOR_TEMPERATURE).set_value(color_temperature) if volume is not None: self.other_config.get_child_by_name(AUDIO_VOLUME).set_value(str(volume)) self.camera.set_config(self.camera_config) # We need this even though no event is triggered wait_for_event(self.camera) gp_jpg_path = self.camera.capture(gp.GP_CAPTURE_IMAGE) gp_dng_path = wait_for_event(self.camera, timeout=TIMEOUT_CAPTURE_DNG, event_type=gp.GP_EVENT_FILE_ADDED) if not gp_dng_path: raise RuntimeError('Unable to copy DNG') jpg_path = os.path.join(gp_jpg_path.folder, gp_jpg_path.name) dng_path = os.path.join(gp_dng_path.folder, gp_dng_path.name) print('Capture took %0.03f sec' % (time.time() - t1, )) return jpg_path, dng_path def download_file(self, src_path, dst_path, delete=True): \"\"\"Copy the file from the camera src_path to local dst_path\"\"\" t1 = time.time() src_folder, src_name = os.path.split(src_path) src_file = self.camera.file_get(src_folder, src_name, gp.GP_FILE_TYPE_NORMAL) print('Download %s ->\\n\\t%s' % (src_path, dst_path)) src_file.save(dst_path) wait_for_event(self.camera) print('Download took %0.03f sec' % (time.time() - t1, )) if delete: t1 = time.time() print('Delete %s' % src_path) self.camera.file_delete(src_folder, src_name) wait_for_event(self.camera) print('Delete took %0.03f sec' % (time.time() - t1, )) def _unittest(): \"\"\"test a short exposure sequence\"\"\" # temporary directory dst_template = '/tmp/theta/capture.%04d.%s' t1 = time.time() camera = CameraUsb() camera.init() print(camera.get_info()) frame = 1 jpg_path, dng_path = camera.take_picture(0) print(jpg_path, dng_path) camera.download_file(dng_path, dst_template % (frame, 'dng')) frame += 1 jpg_path, dng_path = camera.take_picture(24) print(jpg_path, dng_path) camera.download_file(dng_path, dst_template % (frame, 'dng')) frame += 1 jpg_path, dng_path = camera.take_picture(42) print(jpg_path, dng_path) camera.download_file(dng_path, dst_template % (frame, 'dng')) frame += 1 print('Done in %0.03f sec' % (time.time() - t1, )) if __name__ == \"__main__\": _unittest()","title":"Python bindings"},{"location":"meetup_archive/2020_09_01/","text":"September 1, 2020 - First Linux Meetup 45 people signed up and 17 people attended. Due to the US health situation, the meetup was online only using Zoom Pro. It lasted 20 minutes past the planned 60 minutes due to active questions. In addition to configuration questions for libuvc-theta and libuvc-theta-sample, we showed two Linux streaming demos from a Jetson Nano with real-time processing using Python OpenCV. Slides A copy of the slides used in the meetup are here Community Projects - ROS and OpenCV ROS package for RICOH THETA S RICOH THETA S usage package with Ubuntu 16.04 and ROS Kinetic Robotic Intelligence Lab (RobInLab) ROS package rgbd stereo 360 camera rgbd_stereo_360camera convert fisheye images to equirectangular projection obtain depth image from stereo equirectangular image pair using basic SGBM algorithm to estimate disparity depth information using WLS filter in addition to SGBM algorithm Q and A How do I load v4l2loopback automatically when I reboot? In the file /etc/modules-load.d/modules.conf add a new line v4l2loopback . How do I save video to file with the USB API? If you are using the USB to save video to file (not streaming), this command works with the V and Z1. ptpcam -R 0x101c,0,0,1 Can I use OpenVSLAM? It works with a video from file. We didn't test it in the past with a live stream because we didn't have a way to get the live video onto Linux. Please test it now and report back. Discussion . Demo 3 in the video below is with a RICOH THETA V at 1920x960 with FPS of 10. Video How do I access camera acceleration or change of position? You need to use a plug-in to access camera sensor data. Discussion Related info is in this video for a real-time demo. Article summary in English. GitHub repo here . Integrated with TensorFlow Lite using internal camera OS NDK. There is a related article here that shows camera Yaw and Pitch on the OLED of the Z1. gist Do you have plans to additional deep learning? We may based on additional feedback. A good next step is to assess the VOC-360 image dataset that can be used to train models for 360 images. More information on the model and how to download the dataset is here . TensorFlow demo running inside the camera is here . FDDB-360 contains 17,052 fisheye-looking images and a total of 26,640 annotated faces. Did you use DetectNet on 4K frames? (from Craig) For DetectNet, I was only able to test it at 2K on the Jetson Nano due to limited resources. I believe it works at 4k on Jetson Xavier. But, I don't have a Jetson Xavier due to cost Is motionJPEG higher per frame bitrate? Craig: The MotionJPEG is lower fps and higher latency, but it is convenient. There's a demo video of MotionJPEG here: https://youtu.be/5eSdqEudu5s The code is available for testing. Though MotionJPEG is not recommended for AI processing. However, feel free to give it a try. Can we use other THETAs? or only V? Craig: Z1 works Can the THETA S be used for live streaming? From craig to Everyone: 10:39 AM The V and Z1 are the only models that support live streaming of equirectangular The THETA S streams motionJPEG. It should work with Linux in dual-fisheye the V and Z1 stream in UVC 1.5 in equirectangular From john to Everyone: 10:41 AM yes, it works There is latency of 2-3 seconds with Ubuntu 20.04 John \u2192 Had latency of 2-3 seconds \u2192 Couldn\u2019t text it on 16-18 \u2192 How to reduce the latency, what changes need to be made on Ubuntu 16/18? Craig: I used Ubuntu 20. Discrete GPU, John might be using software rendering (if it cannot use GPU). Craig uses x86, did not use software rendering From john to Everyone: 10:55 AM I saw your description in the link and tested for Ubuntu 20.04, but with latency. From john to Everyone: 10:55 AM But couldn't make it work in Ubuntu 16 and 18. Do you know of what modification is required? From craig to Everyone: 10:55 AM I didn't have latency. did you install the gstreamer full plug-in pack? After meetup, ran this test to show latency. you mention it doesn\u2019t work with Raspberry Pi now. We were wondering the reason. Is it because the OS or the CPU architecture (i.e. arm64) ? From Luke Lu to Everyone: 11:01 AM Thanks for your tutorial. In your forum, you mention it doesn\u2019t work with Raspberry Pi now. We were wondering the reason. Is it because the OS or the CPU architecture (i.e. arm64) ? Craig: Cut down resolution and try again. Craig couldn\u2019t get it to work. Nano has DDR4, Pi3 has DDR3. Hardware acceleration. H.264 acceleration doesn\u2019t do decoding. Cut stream down to 2k and try again. Try Pi4 (newest), 2k, assess to see if it works. Speed of decoding is the limiting factor. Do I need to recompile to change the resolution After the meetup, we ran this test using command line arguments. Using the test, you can specify the resolution with: $ ./gst_loopback --format 4K start, hit any key to stop $ ./gst_loopback --format 2K start, hit any key to stop If the THETA is on /dev/video2 , you can confirm resolution with: $ v4l2-ctl --device /dev/video2 --list-formats-ext ioctl: VIDIOC_ENUM_FMT Type: Video Capture [0]: 'YU12' (Planar YUV 4:2:0) Size: Discrete 1920x960 Interval: Discrete 0.033s (30.000 fps) Or if in 4K, $ v4l2-ctl --device /dev/video2 --list-formats-ext ioctl: VIDIOC_ENUM_FMT Type: Video Capture [0]: 'YU12' (Planar YUV 4:2:0) Size: Discrete 3840x1920 Interval: Discrete 0.033s (30.000 fps)","title":"September 1, 2020 - First Linux Meetup"},{"location":"meetup_archive/2020_09_01/#september-1-2020-first-linux-meetup","text":"45 people signed up and 17 people attended. Due to the US health situation, the meetup was online only using Zoom Pro. It lasted 20 minutes past the planned 60 minutes due to active questions. In addition to configuration questions for libuvc-theta and libuvc-theta-sample, we showed two Linux streaming demos from a Jetson Nano with real-time processing using Python OpenCV.","title":"September 1, 2020 - First Linux Meetup"},{"location":"meetup_archive/2020_09_01/#slides","text":"A copy of the slides used in the meetup are here","title":"Slides"},{"location":"meetup_archive/2020_09_01/#community-projects-ros-and-opencv","text":"","title":"Community Projects - ROS and OpenCV"},{"location":"meetup_archive/2020_09_01/#ros-package-for-ricoh-theta-s","text":"RICOH THETA S usage package with Ubuntu 16.04 and ROS Kinetic Robotic Intelligence Lab (RobInLab) ROS package","title":"ROS package for RICOH THETA S"},{"location":"meetup_archive/2020_09_01/#rgbd-stereo-360-camera","text":"rgbd_stereo_360camera convert fisheye images to equirectangular projection obtain depth image from stereo equirectangular image pair using basic SGBM algorithm to estimate disparity depth information using WLS filter in addition to SGBM algorithm","title":"rgbd stereo 360 camera"},{"location":"meetup_archive/2020_09_01/#q-and-a","text":"","title":"Q and A"},{"location":"meetup_archive/2020_09_01/#how-do-i-load-v4l2loopback-automatically-when-i-reboot","text":"In the file /etc/modules-load.d/modules.conf add a new line v4l2loopback .","title":"How do I load v4l2loopback automatically when I reboot?"},{"location":"meetup_archive/2020_09_01/#how-do-i-save-video-to-file-with-the-usb-api","text":"If you are using the USB to save video to file (not streaming), this command works with the V and Z1. ptpcam -R 0x101c,0,0,1","title":"How do I save video to file with the USB API?"},{"location":"meetup_archive/2020_09_01/#can-i-use-openvslam","text":"It works with a video from file. We didn't test it in the past with a live stream because we didn't have a way to get the live video onto Linux. Please test it now and report back. Discussion . Demo 3 in the video below is with a RICOH THETA V at 1920x960 with FPS of 10. Video","title":"Can I use OpenVSLAM?"},{"location":"meetup_archive/2020_09_01/#how-do-i-access-camera-acceleration-or-change-of-position","text":"You need to use a plug-in to access camera sensor data. Discussion Related info is in this video for a real-time demo. Article summary in English. GitHub repo here . Integrated with TensorFlow Lite using internal camera OS NDK. There is a related article here that shows camera Yaw and Pitch on the OLED of the Z1. gist","title":"How do I access camera acceleration or change of position?"},{"location":"meetup_archive/2020_09_01/#do-you-have-plans-to-additional-deep-learning","text":"We may based on additional feedback. A good next step is to assess the VOC-360 image dataset that can be used to train models for 360 images. More information on the model and how to download the dataset is here . TensorFlow demo running inside the camera is here . FDDB-360 contains 17,052 fisheye-looking images and a total of 26,640 annotated faces.","title":"Do you have plans to additional deep learning?"},{"location":"meetup_archive/2020_09_01/#did-you-use-detectnet-on-4k-frames","text":"(from Craig) For DetectNet, I was only able to test it at 2K on the Jetson Nano due to limited resources. I believe it works at 4k on Jetson Xavier. But, I don't have a Jetson Xavier due to cost","title":"Did you use DetectNet on 4K frames?"},{"location":"meetup_archive/2020_09_01/#is-motionjpeg-higher-per-frame-bitrate","text":"Craig: The MotionJPEG is lower fps and higher latency, but it is convenient. There's a demo video of MotionJPEG here: https://youtu.be/5eSdqEudu5s The code is available for testing. Though MotionJPEG is not recommended for AI processing. However, feel free to give it a try.","title":"Is motionJPEG higher per frame bitrate?"},{"location":"meetup_archive/2020_09_01/#can-we-use-other-thetas-or-only-v","text":"Craig: Z1 works","title":"Can we use other THETAs? or only V?"},{"location":"meetup_archive/2020_09_01/#can-the-theta-s-be-used-for-live-streaming","text":"From craig to Everyone: 10:39 AM The V and Z1 are the only models that support live streaming of equirectangular The THETA S streams motionJPEG. It should work with Linux in dual-fisheye the V and Z1 stream in UVC 1.5 in equirectangular From john to Everyone: 10:41 AM yes, it works","title":"Can the THETA S be used for live streaming?"},{"location":"meetup_archive/2020_09_01/#there-is-latency-of-2-3-seconds-with-ubuntu-2004","text":"John \u2192 Had latency of 2-3 seconds \u2192 Couldn\u2019t text it on 16-18 \u2192 How to reduce the latency, what changes need to be made on Ubuntu 16/18? Craig: I used Ubuntu 20. Discrete GPU, John might be using software rendering (if it cannot use GPU). Craig uses x86, did not use software rendering From john to Everyone: 10:55 AM I saw your description in the link and tested for Ubuntu 20.04, but with latency. From john to Everyone: 10:55 AM But couldn't make it work in Ubuntu 16 and 18. Do you know of what modification is required? From craig to Everyone: 10:55 AM I didn't have latency. did you install the gstreamer full plug-in pack? After meetup, ran this test to show latency.","title":"There is latency of 2-3 seconds with Ubuntu 20.04"},{"location":"meetup_archive/2020_09_01/#you-mention-it-doesnt-work-with-raspberry-pi-now-we-were-wondering-the-reason-is-it-because-the-os-or-the-cpu-architecture-ie-arm64","text":"From Luke Lu to Everyone: 11:01 AM Thanks for your tutorial. In your forum, you mention it doesn\u2019t work with Raspberry Pi now. We were wondering the reason. Is it because the OS or the CPU architecture (i.e. arm64) ? Craig: Cut down resolution and try again. Craig couldn\u2019t get it to work. Nano has DDR4, Pi3 has DDR3. Hardware acceleration. H.264 acceleration doesn\u2019t do decoding. Cut stream down to 2k and try again. Try Pi4 (newest), 2k, assess to see if it works. Speed of decoding is the limiting factor.","title":"you mention it doesn\u2019t work with Raspberry Pi now. We were wondering the reason.  Is it because the OS or the CPU architecture (i.e. arm64) ?"},{"location":"meetup_archive/2020_09_01/#do-i-need-to-recompile-to-change-the-resolution","text":"After the meetup, we ran this test using command line arguments. Using the test, you can specify the resolution with: $ ./gst_loopback --format 4K start, hit any key to stop $ ./gst_loopback --format 2K start, hit any key to stop If the THETA is on /dev/video2 , you can confirm resolution with: $ v4l2-ctl --device /dev/video2 --list-formats-ext ioctl: VIDIOC_ENUM_FMT Type: Video Capture [0]: 'YU12' (Planar YUV 4:2:0) Size: Discrete 1920x960 Interval: Discrete 0.033s (30.000 fps) Or if in 4K, $ v4l2-ctl --device /dev/video2 --list-formats-ext ioctl: VIDIOC_ENUM_FMT Type: Video Capture [0]: 'YU12' (Planar YUV 4:2:0) Size: Discrete 3840x1920 Interval: Discrete 0.033s (30.000 fps)","title":"Do I need to recompile to change the resolution"}]}