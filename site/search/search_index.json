{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"RICOH THETA Development on Linux Overview Stream 360 video, control the RICOH THETA API, and supply power to the camera using the USB cable. It's awesome! Video to your Linux computer is 4K at 30fps with under 30ms latency. Works with the RICOH THETA V or RICOH THETA Z1. It's perfect for OpenCV object detection, autonomous drones, building analysis, AI, and TensorFlow projects. The camera can be powered from the USB cable and can switch into live streaming mode, still image, video, or bracket shooting using API commands. We explain the tools, the repos, and the API. Up to date guides, events, and a general pile of great stuff is at the theta360.guide Linux Streaming Site . It's an exciting world. Let's getting started.","title":"Home"},{"location":"#ricoh-theta-development-on-linux","text":"","title":"RICOH THETA Development on Linux"},{"location":"#overview","text":"Stream 360 video, control the RICOH THETA API, and supply power to the camera using the USB cable. It's awesome! Video to your Linux computer is 4K at 30fps with under 30ms latency. Works with the RICOH THETA V or RICOH THETA Z1. It's perfect for OpenCV object detection, autonomous drones, building analysis, AI, and TensorFlow projects. The camera can be powered from the USB cable and can switch into live streaming mode, still image, video, or bracket shooting using API commands. We explain the tools, the repos, and the API. Up to date guides, events, and a general pile of great stuff is at the theta360.guide Linux Streaming Site . It's an exciting world. Let's getting started.","title":"Overview"},{"location":"demos/","text":"Ongoing Tests with Linux Streaming Using Nvidia Jetson Nano live streaming from a THETA V. Processing done with Python3, OpenCV 4.4. Scroll down for code. DetectNet Running live on Jetson Nano with RICOH THETA Z1. DetectNet applied to both single frame with SSD Mobilenet-v2 to assess accuracy and to live stream to assess framerate. Works good on both. Video demo with Jetson Nano . See Jetson Nano inference benchmarks . Code is available in the at https://github.com/dusty-nv/jetson-inference There is super small text in the green box that says, \"person\". The system accurately detected the only person in the image. It is 88.6 percent confident that I am a person. Nice. Despite the distorted view of my feet, the program does detect the human form. Even at night, in low-light conditions with me on the side of the shutter button, the program did detect me. However, there were many frames where I was not detected. To proceed, you will likely need a database of fisheye or equirectangular images to build your own model. Sample Code import jetson.inference import jetson.utils net = jetson.inference.detectNet(\"ssd-mobilenet-v2\", threshold=0.5) camera = jetson.utils.gstCamera(1280, 720, \"/dev/video0\") display = jetson.utils.glDisplay() while display.IsOpen(): img, width, height = camera.CaptureRGBA() detections = net.Detect(img, width, height) display.RenderOnce(img, width, height) display.SetTitle(\"RICOH THETA Detection | Network {:.0f} FPS\".format(net.GetNetworkFPS())) OpenCV Python Works on live stream. Procedure install libuvc-theta install libuv-theta-sample install v4l2loopback load kernel modules for v4l2loopback and verify that /dev/video0 or equivalent shows THETA stream run Python script with cv2 Recommend you recompile OpenCV 4.4 from source code. May take 2.5 hours if you compile on the Nano. Simple Python cv2 Test Frame resize test. import cv2 cap = cv2.VideoCapture(0) # Check if the webcam is opened correctly if not cap.isOpened(): raise IOError(\"Cannot open webcam\") while True: ret, frame = cap.read() frame = cv2.resize(frame, None, fx=0.25, fy=0.25, interpolation=cv2.INTER_AREA) cv2.imshow('Input', frame) c = cv2.waitKey(1) if c == 27: break cap.release() cv2.destroyAllWindows() Build OpenCV One script to install OpenCV 4.3 is from AastaNV here . The script I used is from mdegans here Canny Edge Detection Test Code for OpenCV Demo with Canny from RICOH THETA V . This is the edge detection demo with the white lines on black background. video demo import sys import argparse import cv2 import numpy as np def parse_cli_args(): parser = argparse.ArgumentParser() parser.add_argument(\"--video_device\", dest=\"video_device\", help=\"Video device # of USB webcam (/dev/video?) [0]\", default=0, type=int) arguments = parser.parse_args() return arguments # On versions of L4T previous to L4T 28.1, flip-method=2 # Use the Jetson onboard camera def open_onboard_camera(): return cv2.VideoCapture(0) # Open an external usb camera /dev/videoX def open_camera_device(device_number): return cv2.VideoCapture(device_number) def read_cam(video_capture): if video_capture.isOpened(): windowName = \"main_canny\" cv2.namedWindow(windowName, cv2.WINDOW_NORMAL) cv2.resizeWindow(windowName,1280,720) cv2.moveWindow(windowName,0,0) cv2.setWindowTitle(windowName,\"RICOH THETA OpenCV Python Demo\") showWindow=3 # Show all stages showHelp = True font = cv2.FONT_HERSHEY_PLAIN helpText=\"'Esc' to Quit, '1' for Camera Feed, '2' for Canny Detection, '3' for All Stages. '4' to hide help\" edgeThreshold=40 showFullScreen = False while True: if cv2.getWindowProperty(windowName, 0) < 0: # Check to see if the user closed the window # This will fail if the user closed the window; Nasties get printed to the console break; ret_val, frame = video_capture.read(); hsv=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) blur=cv2.GaussianBlur(hsv,(7,7),1.5) edges=cv2.Canny(blur,0,edgeThreshold) if showWindow == 3: # Need to show the 4 stages # Composite the 2x2 window # Feed from the camera is RGB, the others gray # To composite, convert gray images to color. # All images must be of the same type to display in a window frameRs=cv2.resize(frame, (640,360)) hsvRs=cv2.resize(hsv,(640,360)) vidBuf = np.concatenate((frameRs, cv2.cvtColor(hsvRs,cv2.COLOR_GRAY2BGR)), axis=1) blurRs=cv2.resize(blur,(640,360)) edgesRs=cv2.resize(edges,(640,360)) vidBuf1 = np.concatenate( (cv2.cvtColor(blurRs,cv2.COLOR_GRAY2BGR),cv2.cvtColor(edgesRs,cv2.COLOR_GRAY2BGR)), axis=1) vidBuf = np.concatenate( (vidBuf, vidBuf1), axis=0) if showWindow==1: # Show Camera Frame displayBuf = frame elif showWindow == 2: # Show Canny Edge Detection displayBuf = edges elif showWindow == 3: # Show All Stages displayBuf = vidBuf if showHelp == True: cv2.putText(displayBuf, helpText, (11,20), font, 1.0, (32,32,32), 4, cv2.LINE_AA) cv2.putText(displayBuf, helpText, (10,20), font, 1.0, (240,240,240), 1, cv2.LINE_AA) cv2.imshow(windowName,displayBuf) key=cv2.waitKey(10) if key == 27: # Check for ESC key cv2.destroyAllWindows() break ; elif key==49: # 1 key, show frame cv2.setWindowTitle(windowName,\"Camera Feed\") showWindow=1 elif key==50: # 2 key, show Canny cv2.setWindowTitle(windowName,\"Canny Edge Detection\") showWindow=2 elif key==51: # 3 key, show Stages cv2.setWindowTitle(windowName,\"Camera, Gray scale, Gaussian Blur, Canny Edge Detection\") showWindow=3 elif key==52: # 4 key, toggle help showHelp = not showHelp elif key==44: # , lower canny edge threshold edgeThreshold=max(0,edgeThreshold-1) print ('Canny Edge Threshold Maximum: ',edgeThreshold) elif key==46: # , raise canny edge threshold edgeThreshold=edgeThreshold+1 print ('Canny Edge Threshold Maximum: ', edgeThreshold) elif key==74: # Toggle fullscreen; This is the F3 key on this particular keyboard # Toggle full screen mode if showFullScreen == False : cv2.setWindowProperty(windowName, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN) else: cv2.setWindowProperty(windowName, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL) showFullScreen = not showFullScreen else: print (\"camera open failed\") if __name__ == '__main__': arguments = parse_cli_args() print(\"Called with args:\") print(arguments) print(\"OpenCV version: {}\".format(cv2.__version__)) print(\"Device Number:\",arguments.video_device) if arguments.video_device==0: video_capture=open_onboard_camera() else: video_capture=open_camera_device(arguments.video_device) read_cam(video_capture) video_capture.release() cv2.destroyAllWindows() OpenPose Works on live stream with Jetpack 4.3, not 4.4.","title":"Demos"},{"location":"demos/#ongoing-tests-with-linux-streaming","text":"Using Nvidia Jetson Nano live streaming from a THETA V. Processing done with Python3, OpenCV 4.4. Scroll down for code.","title":"Ongoing Tests with Linux Streaming"},{"location":"demos/#detectnet","text":"Running live on Jetson Nano with RICOH THETA Z1. DetectNet applied to both single frame with SSD Mobilenet-v2 to assess accuracy and to live stream to assess framerate. Works good on both. Video demo with Jetson Nano . See Jetson Nano inference benchmarks . Code is available in the at https://github.com/dusty-nv/jetson-inference There is super small text in the green box that says, \"person\". The system accurately detected the only person in the image. It is 88.6 percent confident that I am a person. Nice. Despite the distorted view of my feet, the program does detect the human form. Even at night, in low-light conditions with me on the side of the shutter button, the program did detect me. However, there were many frames where I was not detected. To proceed, you will likely need a database of fisheye or equirectangular images to build your own model.","title":"DetectNet"},{"location":"demos/#sample-code","text":"import jetson.inference import jetson.utils net = jetson.inference.detectNet(\"ssd-mobilenet-v2\", threshold=0.5) camera = jetson.utils.gstCamera(1280, 720, \"/dev/video0\") display = jetson.utils.glDisplay() while display.IsOpen(): img, width, height = camera.CaptureRGBA() detections = net.Detect(img, width, height) display.RenderOnce(img, width, height) display.SetTitle(\"RICOH THETA Detection | Network {:.0f} FPS\".format(net.GetNetworkFPS()))","title":"Sample Code"},{"location":"demos/#opencv-python","text":"Works on live stream.","title":"OpenCV Python"},{"location":"demos/#procedure","text":"install libuvc-theta install libuv-theta-sample install v4l2loopback load kernel modules for v4l2loopback and verify that /dev/video0 or equivalent shows THETA stream run Python script with cv2 Recommend you recompile OpenCV 4.4 from source code. May take 2.5 hours if you compile on the Nano.","title":"Procedure"},{"location":"demos/#simple-python-cv2-test","text":"Frame resize test. import cv2 cap = cv2.VideoCapture(0) # Check if the webcam is opened correctly if not cap.isOpened(): raise IOError(\"Cannot open webcam\") while True: ret, frame = cap.read() frame = cv2.resize(frame, None, fx=0.25, fy=0.25, interpolation=cv2.INTER_AREA) cv2.imshow('Input', frame) c = cv2.waitKey(1) if c == 27: break cap.release() cv2.destroyAllWindows()","title":"Simple Python cv2 Test"},{"location":"demos/#build-opencv","text":"One script to install OpenCV 4.3 is from AastaNV here . The script I used is from mdegans here","title":"Build OpenCV"},{"location":"demos/#canny-edge-detection-test","text":"Code for OpenCV Demo with Canny from RICOH THETA V . This is the edge detection demo with the white lines on black background. video demo import sys import argparse import cv2 import numpy as np def parse_cli_args(): parser = argparse.ArgumentParser() parser.add_argument(\"--video_device\", dest=\"video_device\", help=\"Video device # of USB webcam (/dev/video?) [0]\", default=0, type=int) arguments = parser.parse_args() return arguments # On versions of L4T previous to L4T 28.1, flip-method=2 # Use the Jetson onboard camera def open_onboard_camera(): return cv2.VideoCapture(0) # Open an external usb camera /dev/videoX def open_camera_device(device_number): return cv2.VideoCapture(device_number) def read_cam(video_capture): if video_capture.isOpened(): windowName = \"main_canny\" cv2.namedWindow(windowName, cv2.WINDOW_NORMAL) cv2.resizeWindow(windowName,1280,720) cv2.moveWindow(windowName,0,0) cv2.setWindowTitle(windowName,\"RICOH THETA OpenCV Python Demo\") showWindow=3 # Show all stages showHelp = True font = cv2.FONT_HERSHEY_PLAIN helpText=\"'Esc' to Quit, '1' for Camera Feed, '2' for Canny Detection, '3' for All Stages. '4' to hide help\" edgeThreshold=40 showFullScreen = False while True: if cv2.getWindowProperty(windowName, 0) < 0: # Check to see if the user closed the window # This will fail if the user closed the window; Nasties get printed to the console break; ret_val, frame = video_capture.read(); hsv=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) blur=cv2.GaussianBlur(hsv,(7,7),1.5) edges=cv2.Canny(blur,0,edgeThreshold) if showWindow == 3: # Need to show the 4 stages # Composite the 2x2 window # Feed from the camera is RGB, the others gray # To composite, convert gray images to color. # All images must be of the same type to display in a window frameRs=cv2.resize(frame, (640,360)) hsvRs=cv2.resize(hsv,(640,360)) vidBuf = np.concatenate((frameRs, cv2.cvtColor(hsvRs,cv2.COLOR_GRAY2BGR)), axis=1) blurRs=cv2.resize(blur,(640,360)) edgesRs=cv2.resize(edges,(640,360)) vidBuf1 = np.concatenate( (cv2.cvtColor(blurRs,cv2.COLOR_GRAY2BGR),cv2.cvtColor(edgesRs,cv2.COLOR_GRAY2BGR)), axis=1) vidBuf = np.concatenate( (vidBuf, vidBuf1), axis=0) if showWindow==1: # Show Camera Frame displayBuf = frame elif showWindow == 2: # Show Canny Edge Detection displayBuf = edges elif showWindow == 3: # Show All Stages displayBuf = vidBuf if showHelp == True: cv2.putText(displayBuf, helpText, (11,20), font, 1.0, (32,32,32), 4, cv2.LINE_AA) cv2.putText(displayBuf, helpText, (10,20), font, 1.0, (240,240,240), 1, cv2.LINE_AA) cv2.imshow(windowName,displayBuf) key=cv2.waitKey(10) if key == 27: # Check for ESC key cv2.destroyAllWindows() break ; elif key==49: # 1 key, show frame cv2.setWindowTitle(windowName,\"Camera Feed\") showWindow=1 elif key==50: # 2 key, show Canny cv2.setWindowTitle(windowName,\"Canny Edge Detection\") showWindow=2 elif key==51: # 3 key, show Stages cv2.setWindowTitle(windowName,\"Camera, Gray scale, Gaussian Blur, Canny Edge Detection\") showWindow=3 elif key==52: # 4 key, toggle help showHelp = not showHelp elif key==44: # , lower canny edge threshold edgeThreshold=max(0,edgeThreshold-1) print ('Canny Edge Threshold Maximum: ',edgeThreshold) elif key==46: # , raise canny edge threshold edgeThreshold=edgeThreshold+1 print ('Canny Edge Threshold Maximum: ', edgeThreshold) elif key==74: # Toggle fullscreen; This is the F3 key on this particular keyboard # Toggle full screen mode if showFullScreen == False : cv2.setWindowProperty(windowName, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN) else: cv2.setWindowProperty(windowName, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL) showFullScreen = not showFullScreen else: print (\"camera open failed\") if __name__ == '__main__': arguments = parse_cli_args() print(\"Called with args:\") print(arguments) print(\"OpenCV version: {}\".format(cv2.__version__)) print(\"Device Number:\",arguments.video_device) if arguments.video_device==0: video_capture=open_onboard_camera() else: video_capture=open_camera_device(arguments.video_device) read_cam(video_capture) video_capture.release() cv2.destroyAllWindows()","title":"Canny Edge Detection Test"},{"location":"demos/#openpose","text":"Works on live stream with Jetpack 4.3, not 4.4.","title":"OpenPose"},{"location":"equipment/","text":"Hardware Requirements for Linux and the RICOH THETA Jetson Nano - Reference Platform Our reference platform is the NVIDIA Jetson Nano running JetPack 4.4, which is Ubuntu 18.04. The Nano is an ARM A57 with a 128-core Maxwell GPU, 4GB 64-bit LPDDR4. The nano is powered by a 5V 4A barrel connector, not the microUSB which is 5V 2A. Our Nano has an external fan on the PWM header and a 64GB microSD card. x86 Linux We've also tested the libuvc-theta (streaming) and libuvc-theta-sample (streaming sample application) on x86 64bit Linux using Ubuntu 20.04 LTS, Focal Fossa. We've tested v4l2loopback with gst_loopback on a low-end Pentium x86 computer. It works fine. Thanks to commuity member Yu You for this fix to gst_view.c. Note the addition of qos=false to the pipeline. This is currently on line 190 . if (strcmp(cmd_name, \"gst_loopback\") == 0) pipe_proc = \"decodebin ! autovideoconvert ! \" \"video/x-raw,format=I420 ! identity drop-allocation=true !\" \"v4l2sink device=/dev/video0 qos=false sync=false\"; Screenshot of loopback running on /dev/video0 , tested with vlc. Addtional x86 Information If you're having problems after making the modification described above, you can try to temporarily disable your dedicated graphics card on x86. In our tests on Ubuntu 20, Focal Fossa, the gstreamer vaapi plugin can't use the hardware decoder on the NVIDIA GPU with the proprietary NVIDIA driver. The causes gstreamer to use a software decoder instead. This will likely cause many frame drops on your system. You can verify this by setting the GST_DEBUG environment variable to 2 or 3 and then running gst_loopback. You will likely see many frame drop messages. There are two possible workarounds: Use the nvdec plugin Although the nvdec plugin is a part of the gstreamer-plugins-bad, it is not included in binary distribution due to license problem. Thus, you have to build the plugin by yourself. You also need to modify the pipeline of the gst_loopback accordingly. Use hardware decoder on the iGPU You may need additional setup to run X server on the iGPU, Raspberry Pi The Raspberry Pi will work great with the USB API. However, you will not have a good experience streaming 4K, even with the Raspberry Pi 4. The Raspberry Pi's H.264 hardware decoder does not support 4K resolution even on the Raspberry Pi4. In addition, older Pis' (Pi to Pi3) memory bandwidth(32bit DDR2) is too poor to handle even FHD stream from THETA V/Z1. NVIDIA Jetson Xavier On Jetson Xavier, auto plugin selection of the gstreamer seems to be not working well, replacing \"decodebin ! autovideosink sync=false\" to \"nvv4l2decoder ! nv3dsink sync=false\" will solve the problem. Edit this line in the sample code and recompile.","title":"Equipment"},{"location":"equipment/#hardware-requirements-for-linux-and-the-ricoh-theta","text":"","title":"Hardware Requirements for Linux and the RICOH THETA"},{"location":"equipment/#jetson-nano-reference-platform","text":"Our reference platform is the NVIDIA Jetson Nano running JetPack 4.4, which is Ubuntu 18.04. The Nano is an ARM A57 with a 128-core Maxwell GPU, 4GB 64-bit LPDDR4. The nano is powered by a 5V 4A barrel connector, not the microUSB which is 5V 2A. Our Nano has an external fan on the PWM header and a 64GB microSD card.","title":"Jetson Nano - Reference Platform"},{"location":"equipment/#x86-linux","text":"We've also tested the libuvc-theta (streaming) and libuvc-theta-sample (streaming sample application) on x86 64bit Linux using Ubuntu 20.04 LTS, Focal Fossa. We've tested v4l2loopback with gst_loopback on a low-end Pentium x86 computer. It works fine. Thanks to commuity member Yu You for this fix to gst_view.c. Note the addition of qos=false to the pipeline. This is currently on line 190 . if (strcmp(cmd_name, \"gst_loopback\") == 0) pipe_proc = \"decodebin ! autovideoconvert ! \" \"video/x-raw,format=I420 ! identity drop-allocation=true !\" \"v4l2sink device=/dev/video0 qos=false sync=false\"; Screenshot of loopback running on /dev/video0 , tested with vlc.","title":"x86 Linux"},{"location":"equipment/#addtional-x86-information","text":"If you're having problems after making the modification described above, you can try to temporarily disable your dedicated graphics card on x86. In our tests on Ubuntu 20, Focal Fossa, the gstreamer vaapi plugin can't use the hardware decoder on the NVIDIA GPU with the proprietary NVIDIA driver. The causes gstreamer to use a software decoder instead. This will likely cause many frame drops on your system. You can verify this by setting the GST_DEBUG environment variable to 2 or 3 and then running gst_loopback. You will likely see many frame drop messages. There are two possible workarounds: Use the nvdec plugin Although the nvdec plugin is a part of the gstreamer-plugins-bad, it is not included in binary distribution due to license problem. Thus, you have to build the plugin by yourself. You also need to modify the pipeline of the gst_loopback accordingly. Use hardware decoder on the iGPU You may need additional setup to run X server on the iGPU,","title":"Addtional x86 Information"},{"location":"equipment/#raspberry-pi","text":"The Raspberry Pi will work great with the USB API. However, you will not have a good experience streaming 4K, even with the Raspberry Pi 4. The Raspberry Pi's H.264 hardware decoder does not support 4K resolution even on the Raspberry Pi4. In addition, older Pis' (Pi to Pi3) memory bandwidth(32bit DDR2) is too poor to handle even FHD stream from THETA V/Z1.","title":"Raspberry Pi"},{"location":"equipment/#nvidia-jetson-xavier","text":"On Jetson Xavier, auto plugin selection of the gstreamer seems to be not working well, replacing \"decodebin ! autovideosink sync=false\" to \"nvv4l2decoder ! nv3dsink sync=false\" will solve the problem. Edit this line in the sample code and recompile.","title":"NVIDIA Jetson Xavier"},{"location":"help/","text":"Getting Help Updated Docs and Events Community discussion - Linux Streaming Community discussion - USB API FAQ Can I stream indefinitely? The THETA Z1 can power off the USB-C port and stream at the same time. Using USB 3.0 or better, the charge increases in our tests. The camera does get hot. Upgrade to the latest firmware. If possible, attach a small fan to your tripod and point it at the body of the THETA. The V drains slowly. It will last about 8 hours. You may be able to bypass the battery, but this is not tested. /dev/video0 freezes on x86 Change line 190 of gst_viewer.c. if (strcmp(cmd_name, \"gst_loopback\") == 0) pipe_proc = \"decodebin ! autovideoconvert ! \" \"video/x-raw,format=I420 ! identity drop-allocation=true !\" \"v4l2sink device=/dev/video0 qos=false sync=false\"; The THETA is not appearing on /dev/video0 Install v4l2loopback . How do I reduce the default 4K stream to 2K to improve AI processing? If your AI processing is going to slowly, try to reduce resolution from 4K to 2K. You likely need to do this on Jetson Nano as 4K often hangs due to limited resources on Nano. In gst_viewer.c, change line 248 from THETAUVC_MODE_UHD_2997 to THETAUVC_MODE_FHD_2997. Refer to thetauvc.c#L55 for definition. I can't use it on Xavier Change to: \"nvv4l2decoder ! nv3dsink sync=false\"","title":"Help"},{"location":"help/#getting-help","text":"Updated Docs and Events Community discussion - Linux Streaming Community discussion - USB API","title":"Getting Help"},{"location":"help/#faq","text":"","title":"FAQ"},{"location":"help/#can-i-stream-indefinitely","text":"The THETA Z1 can power off the USB-C port and stream at the same time. Using USB 3.0 or better, the charge increases in our tests. The camera does get hot. Upgrade to the latest firmware. If possible, attach a small fan to your tripod and point it at the body of the THETA. The V drains slowly. It will last about 8 hours. You may be able to bypass the battery, but this is not tested.","title":"Can I stream indefinitely?"},{"location":"help/#devvideo0-freezes-on-x86","text":"Change line 190 of gst_viewer.c. if (strcmp(cmd_name, \"gst_loopback\") == 0) pipe_proc = \"decodebin ! autovideoconvert ! \" \"video/x-raw,format=I420 ! identity drop-allocation=true !\" \"v4l2sink device=/dev/video0 qos=false sync=false\";","title":"/dev/video0 freezes on x86"},{"location":"help/#the-theta-is-not-appearing-on-devvideo0","text":"Install v4l2loopback .","title":"The THETA is not appearing on /dev/video0"},{"location":"help/#how-do-i-reduce-the-default-4k-stream-to-2k-to-improve-ai-processing","text":"If your AI processing is going to slowly, try to reduce resolution from 4K to 2K. You likely need to do this on Jetson Nano as 4K often hangs due to limited resources on Nano. In gst_viewer.c, change line 248 from THETAUVC_MODE_UHD_2997 to THETAUVC_MODE_FHD_2997. Refer to thetauvc.c#L55 for definition.","title":"How do I reduce the default 4K stream to 2K to improve AI processing?"},{"location":"help/#i-cant-use-it-on-xavier","text":"Change to: \"nvv4l2decoder ! nv3dsink sync=false\"","title":"I can't use it on Xavier"},{"location":"software/","text":"Software Requirements Live Streaming You need to download the two GitHub repos below and compile the driver and sample code. libuvc-theta libuvc-theta-sample If you want to use /dev/video0 , you will also need v4l2loopback In addition, there are numerous dependencies to compile the tools listed above. However, have no fear, we will walk you through it. How To Compile and Install Build and install on x86 Ubuntu 20.04 Jetson Nano with OpenCV and VLC on /dev/video0 Compile libuvc-theta on Jetson Nano - silent screencast Build and run v4l2loopback on Jetson Nano . Needed for /dev/video0 USB API libptp - next section for detailed walkthrough","title":"Software"},{"location":"software/#software-requirements","text":"","title":"Software Requirements"},{"location":"software/#live-streaming","text":"You need to download the two GitHub repos below and compile the driver and sample code. libuvc-theta libuvc-theta-sample If you want to use /dev/video0 , you will also need v4l2loopback In addition, there are numerous dependencies to compile the tools listed above. However, have no fear, we will walk you through it.","title":"Live Streaming"},{"location":"software/#how-to-compile-and-install","text":"Build and install on x86 Ubuntu 20.04 Jetson Nano with OpenCV and VLC on /dev/video0 Compile libuvc-theta on Jetson Nano - silent screencast Build and run v4l2loopback on Jetson Nano . Needed for /dev/video0","title":"How To Compile and Install"},{"location":"software/#usb-api","text":"libptp - next section for detailed walkthrough","title":"USB API"},{"location":"usb_api/","text":"Setup libptp Download libptp source libptp - Picture Transfer Protocol lib Get the newest version, which is 2-1.2 right now. build libptp $ ./configure $ make If you have a build error when compiling libusb, you may need to install the development libraries for libusb. install libusb-dev $ sudo apt install libusb-dev You may not need this step if you already have the libusb development libraries installed. install libptp $ sudo make install set /usr/local/lib in library path The default location of the libptp install is /usr/local/lib . Make sure that this is in your library path. If it isn't, add it to a file such as libc.conf in /etc/ld.so.conf/ . $ cd /etc/ld.so.conf.d/ $ ls $ cat libc.conf run ldconfig Load the library configuration. $ sudo /sbin/ldconfig -v Test ptpcam Connect RICOH THETA to Jetson with a USB cable. Version of 2-1.2 of libptp has a bug in it. Although ptpcam does take pictures and function normally, you will see an error about capture status. Fix problem with libptp response Go to line 77 of ptp.h and change PTP_USB_INT_PACKET_LEN to 28 . After modification, the code will look like this. Using USB API test ptpcam response again Take a still image picture with ptpcam --capture . Set camera to live streaming mode Check on camera mode. $ ptpcam --show-property=0x5013 Set to live streaming mode. $ ptpcam --set-property=0x5013 --val=0x8005 Using the official RICOH USB API documentation , you can verify that 0x8005 is live streaming mode. The camera LED should show that the THETA is in LIVE mode. In our tests, the RICOH THETA Z1 could charge while streaming over a USB 3.0 port (blue insert). After hours of streaming, the Z1 LED looks like this. The response codes are shown below. 0x0001 = single-shot shooting 0x0003 = Interval shooting 0x8002 = Movie shooting 0x8003 = Interval composite shooting 0x8004 = Multi bracket shooting 0x8005 = Live streaming 0x8006 = Interval shooting - tripod stabilizatio is off (top/bottom correction and stitching optimized) 0x8007 = Interval shooting - tripod stabilization is on If you set the camera back to still image, single shot mode, you will see this response. $ ptpcam --set-property=0x5013 --val=0x0001 Camera: RICOH THETA V 'Still Capture Mode' is set to: 0x8005 (-32763) Changing property value to 0x0001 [(null)] succeeded. Wake Camera From Sleep In this test, I have the Z1 power off disabled. I left the camera in sleep mode overnight. When I woke up in the morning, I work the Z1 up using an ssh session into the Jetson Nano and running this command. $ ptpcam --set-property=0xD80E --val=0x00 Camera: RICOH THETA Z1 'UNKNOWN' is set to: 1 Changing property value to 0x00 [(null)] succeeded. I tested the camera with the info command. $ ptpcam --info Camera information ================== Model: RICOH THETA Z1 manufacturer: Ricoh Company, Ltd. serial number: '10010104' device version: 1.50.1 extension ID: 0x00000006 extension description: (null) extension version: 0x006e In my initial tests, I had to run the info command twice after I woke the camera up from sleep. The first time, I could not open the session. I got this error. $ ptpcam --info ERROR: Could not open session! In the future, I'll run more tests using the camera FunctionalMode to check status. Put Camera in Still Image Mode You may want to take a detailed picture of the scene based on triggers from the live stream. To do this, you need to take the camera out of live streaming mode and put it into still image mode. In the example below, I wrapped ptpcam in a script that explains the hexcode properties of the mode settings. This helps me with testing. $ ptpcam --set-property=0x5013 --val=0x0001 Camera: RICOH THETA Z1 'Still Capture Mode' is set to: [Normal] Changing property value to 0x0001 [(null)] succeeded. 0x0001 = single-shot shooting 0x0003 = Interval shooting 0x8002 = Movie shooting 0x8003 = Interval composite shooting 0x8004 = Multi bracket shooting 0x8005 = Live streaming 0x8006 = Interval shooting - tripod stabilizatio is off (top/bottom correction and stitching optimized) 0x8007 = Interval shooting - tripod stabilization is on You can verify the mode of with 0x5013. $ ptpcam --show-property=0x5013 Camera: RICOH THETA Z1 'Still Capture Mode' is set to: [Normal] Compare this with the result when the camera is in live streaming mode. $ ptpcam --show-property=0x5013 Camera: RICOH THETA Z1 'Still Capture Mode' is set to: 0x8005 (-32763) 0x0001 = single-shot shooting 0x0003 = Interval shooting 0x8002 = Movie shooting 0x8003 = Interval composite shooting 0x8004 = Multi bracket shooting 0x8005 = Live streaming 0x8006 = Interval shooting - tripod stabilizatio is off (top/bottom correction and stitching optimized) 0x8007 = Interval shooting - tripod stabilization is on","title":"USB API"},{"location":"usb_api/#setup-libptp","text":"","title":"Setup libptp"},{"location":"usb_api/#download-libptp-source","text":"libptp - Picture Transfer Protocol lib Get the newest version, which is 2-1.2 right now.","title":"Download libptp source"},{"location":"usb_api/#build-libptp","text":"$ ./configure $ make If you have a build error when compiling libusb, you may need to install the development libraries for libusb.","title":"build libptp"},{"location":"usb_api/#install-libusb-dev","text":"$ sudo apt install libusb-dev You may not need this step if you already have the libusb development libraries installed.","title":"install libusb-dev"},{"location":"usb_api/#install-libptp","text":"$ sudo make install","title":"install libptp"},{"location":"usb_api/#set-usrlocallib-in-library-path","text":"The default location of the libptp install is /usr/local/lib . Make sure that this is in your library path. If it isn't, add it to a file such as libc.conf in /etc/ld.so.conf/ . $ cd /etc/ld.so.conf.d/ $ ls $ cat libc.conf","title":"set /usr/local/lib in library path"},{"location":"usb_api/#run-ldconfig","text":"Load the library configuration. $ sudo /sbin/ldconfig -v","title":"run ldconfig"},{"location":"usb_api/#test-ptpcam","text":"Connect RICOH THETA to Jetson with a USB cable. Version of 2-1.2 of libptp has a bug in it. Although ptpcam does take pictures and function normally, you will see an error about capture status.","title":"Test ptpcam"},{"location":"usb_api/#fix-problem-with-libptp-response","text":"Go to line 77 of ptp.h and change PTP_USB_INT_PACKET_LEN to 28 . After modification, the code will look like this.","title":"Fix problem with libptp response"},{"location":"usb_api/#using-usb-api","text":"","title":"Using USB API"},{"location":"usb_api/#test-ptpcam-response-again","text":"Take a still image picture with ptpcam --capture .","title":"test ptpcam response again"},{"location":"usb_api/#set-camera-to-live-streaming-mode","text":"Check on camera mode. $ ptpcam --show-property=0x5013 Set to live streaming mode. $ ptpcam --set-property=0x5013 --val=0x8005 Using the official RICOH USB API documentation , you can verify that 0x8005 is live streaming mode. The camera LED should show that the THETA is in LIVE mode. In our tests, the RICOH THETA Z1 could charge while streaming over a USB 3.0 port (blue insert). After hours of streaming, the Z1 LED looks like this. The response codes are shown below. 0x0001 = single-shot shooting 0x0003 = Interval shooting 0x8002 = Movie shooting 0x8003 = Interval composite shooting 0x8004 = Multi bracket shooting 0x8005 = Live streaming 0x8006 = Interval shooting - tripod stabilizatio is off (top/bottom correction and stitching optimized) 0x8007 = Interval shooting - tripod stabilization is on If you set the camera back to still image, single shot mode, you will see this response. $ ptpcam --set-property=0x5013 --val=0x0001 Camera: RICOH THETA V 'Still Capture Mode' is set to: 0x8005 (-32763) Changing property value to 0x0001 [(null)] succeeded.","title":"Set camera to live streaming mode"},{"location":"usb_api/#wake-camera-from-sleep","text":"In this test, I have the Z1 power off disabled. I left the camera in sleep mode overnight. When I woke up in the morning, I work the Z1 up using an ssh session into the Jetson Nano and running this command. $ ptpcam --set-property=0xD80E --val=0x00 Camera: RICOH THETA Z1 'UNKNOWN' is set to: 1 Changing property value to 0x00 [(null)] succeeded. I tested the camera with the info command. $ ptpcam --info Camera information ================== Model: RICOH THETA Z1 manufacturer: Ricoh Company, Ltd. serial number: '10010104' device version: 1.50.1 extension ID: 0x00000006 extension description: (null) extension version: 0x006e In my initial tests, I had to run the info command twice after I woke the camera up from sleep. The first time, I could not open the session. I got this error. $ ptpcam --info ERROR: Could not open session! In the future, I'll run more tests using the camera FunctionalMode to check status.","title":"Wake Camera From Sleep"},{"location":"usb_api/#put-camera-in-still-image-mode","text":"You may want to take a detailed picture of the scene based on triggers from the live stream. To do this, you need to take the camera out of live streaming mode and put it into still image mode. In the example below, I wrapped ptpcam in a script that explains the hexcode properties of the mode settings. This helps me with testing. $ ptpcam --set-property=0x5013 --val=0x0001 Camera: RICOH THETA Z1 'Still Capture Mode' is set to: [Normal] Changing property value to 0x0001 [(null)] succeeded. 0x0001 = single-shot shooting 0x0003 = Interval shooting 0x8002 = Movie shooting 0x8003 = Interval composite shooting 0x8004 = Multi bracket shooting 0x8005 = Live streaming 0x8006 = Interval shooting - tripod stabilizatio is off (top/bottom correction and stitching optimized) 0x8007 = Interval shooting - tripod stabilization is on You can verify the mode of with 0x5013. $ ptpcam --show-property=0x5013 Camera: RICOH THETA Z1 'Still Capture Mode' is set to: [Normal] Compare this with the result when the camera is in live streaming mode. $ ptpcam --show-property=0x5013 Camera: RICOH THETA Z1 'Still Capture Mode' is set to: 0x8005 (-32763) 0x0001 = single-shot shooting 0x0003 = Interval shooting 0x8002 = Movie shooting 0x8003 = Interval composite shooting 0x8004 = Multi bracket shooting 0x8005 = Live streaming 0x8006 = Interval shooting - tripod stabilizatio is off (top/bottom correction and stitching optimized) 0x8007 = Interval shooting - tripod stabilization is on","title":"Put Camera in Still Image Mode"}]}